{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95325ea6",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'gbk' codec can't decode byte 0x8b in position 123: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\桌面\\咸鱼2305\\_____京东富士拍立得相机消费者评论数据分析\\聚类.ipynb 单元格 1\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%E6%A1%8C%E9%9D%A2/%E5%92%B8%E9%B1%BC2305/_____%E4%BA%AC%E4%B8%9C%E5%AF%8C%E5%A3%AB%E6%8B%8D%E7%AB%8B%E5%BE%97%E7%9B%B8%E6%9C%BA%E6%B6%88%E8%B4%B9%E8%80%85%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E8%81%9A%E7%B1%BB.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgensim\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%E6%A1%8C%E9%9D%A2/%E5%92%B8%E9%B1%BC2305/_____%E4%BA%AC%E4%B8%9C%E5%AF%8C%E5%A3%AB%E6%8B%8D%E7%AB%8B%E5%BE%97%E7%9B%B8%E6%9C%BA%E6%B6%88%E8%B4%B9%E8%80%85%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E8%81%9A%E7%B1%BB.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpprint\u001b[39;00m \u001b[39mimport\u001b[39;00m pprint\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/%E6%A1%8C%E9%9D%A2/%E5%92%B8%E9%B1%BC2305/_____%E4%BA%AC%E4%B8%9C%E5%AF%8C%E5%A3%AB%E6%8B%8D%E7%AB%8B%E5%BE%97%E7%9B%B8%E6%9C%BA%E6%B6%88%E8%B4%B9%E8%80%85%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E8%81%9A%E7%B1%BB.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdata_topic.xlsx\u001b[39;49m\u001b[39m\"\u001b[39;49m,encoding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgbk\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%E6%A1%8C%E9%9D%A2/%E5%92%B8%E9%B1%BC2305/_____%E4%BA%AC%E4%B8%9C%E5%AF%8C%E5%A3%AB%E6%8B%8D%E7%AB%8B%E5%BE%97%E7%9B%B8%E6%9C%BA%E6%B6%88%E8%B4%B9%E8%80%85%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E8%81%9A%E7%B1%BB.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m content \u001b[39m=\u001b[39m data[\u001b[39m\"\u001b[39m\u001b[39m评论内容\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mreplace(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[0-9]\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,regex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/%E6%A1%8C%E9%9D%A2/%E5%92%B8%E9%B1%BC2305/_____%E4%BA%AC%E4%B8%9C%E5%AF%8C%E5%A3%AB%E6%8B%8D%E7%AB%8B%E5%BE%97%E7%9B%B8%E6%9C%BA%E6%B6%88%E8%B4%B9%E8%80%85%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E8%81%9A%E7%B1%BB.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m sentence_cut \u001b[39m=\u001b[39m [jieba\u001b[39m.\u001b[39mlcut(line) \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m content]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1723\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1720\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1722\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1723\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n\u001b[0;32m   1724\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1725\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39mif\u001b[39;00m kwds[\u001b[39m\"\u001b[39m\u001b[39mdtype_backend\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[39m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39;49mTextReader(src, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mparsers.pyx:579\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:668\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:879\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:890\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2050\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'gbk' codec can't decode byte 0x8b in position 123: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import csv\n",
    "import gensim\n",
    "from pprint import pprint\n",
    "\n",
    "data = pd.read_csv(r\"data_topic.xlsx\",encoding=\"gbk\")\n",
    "content = data[\"评论内容\"].str.replace(r\"[0-9]\",\"\",regex=True)\n",
    "\n",
    "sentence_cut = [jieba.lcut(line) for line in content]\n",
    "stopwords = pd.read_csv(r\"datas\\停用词表\\哈工大停用词表.txt\",header=None,quoting = csv.QUOTE_NONE,delimiter=\"\\t\")\n",
    "stopwords = stopwords[0].tolist()\n",
    "new_stopwords = pd.read_csv(r\"datas\\停用词表\\中文停用词库.txt\",header=None)\n",
    "stopwords.extend(new_stopwords[0].tolist())\n",
    "#模型构建\n",
    "not_stopwords = [[word for word in line if word not in stopwords and len(word)>1]for line in sentence_cut]\n",
    "#送进模型里获得词向量\n",
    "model =gensim.models.Word2Vec(not_stopwords,min_count=185,window=5) \n",
    "#获得所有词汇\n",
    "words = list(model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "835d30cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'not_stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\桌面\\咸鱼2305\\_____京东富士拍立得相机消费者评论数据分析\\聚类.ipynb 单元格 2\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%E6%A1%8C%E9%9D%A2/%E5%92%B8%E9%B1%BC2305/_____%E4%BA%AC%E4%B8%9C%E5%AF%8C%E5%A3%AB%E6%8B%8D%E7%AB%8B%E5%BE%97%E7%9B%B8%E6%9C%BA%E6%B6%88%E8%B4%B9%E8%80%85%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E8%81%9A%E7%B1%BB.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m defaultdict\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%E6%A1%8C%E9%9D%A2/%E5%92%B8%E9%B1%BC2305/_____%E4%BA%AC%E4%B8%9C%E5%AF%8C%E5%A3%AB%E6%8B%8D%E7%AB%8B%E5%BE%97%E7%9B%B8%E6%9C%BA%E6%B6%88%E8%B4%B9%E8%80%85%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E8%81%9A%E7%B1%BB.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m frequency \u001b[39m=\u001b[39mdefaultdict(\u001b[39mint\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/%E6%A1%8C%E9%9D%A2/%E5%92%B8%E9%B1%BC2305/_____%E4%BA%AC%E4%B8%9C%E5%AF%8C%E5%A3%AB%E6%8B%8D%E7%AB%8B%E5%BE%97%E7%9B%B8%E6%9C%BA%E6%B6%88%E8%B4%B9%E8%80%85%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E8%81%9A%E7%B1%BB.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m not_stopwords:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%E6%A1%8C%E9%9D%A2/%E5%92%B8%E9%B1%BC2305/_____%E4%BA%AC%E4%B8%9C%E5%AF%8C%E5%A3%AB%E6%8B%8D%E7%AB%8B%E5%BE%97%E7%9B%B8%E6%9C%BA%E6%B6%88%E8%B4%B9%E8%80%85%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E8%81%9A%E7%B1%BB.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m line:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%E6%A1%8C%E9%9D%A2/%E5%92%B8%E9%B1%BC2305/_____%E4%BA%AC%E4%B8%9C%E5%AF%8C%E5%A3%AB%E6%8B%8D%E7%AB%8B%E5%BE%97%E7%9B%B8%E6%9C%BA%E6%B6%88%E8%B4%B9%E8%80%85%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E8%81%9A%E7%B1%BB.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         frequency[token] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'not_stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "#获得词频\n",
    "from collections import defaultdict\n",
    "frequency =defaultdict(int)\n",
    "for line in not_stopwords:\n",
    "    for token in line:\n",
    "        frequency[token] +=1\n",
    "words_frequency = [frequency[word] for word in words]\n",
    "word_frequency = pd.DataFrame({\"单词\":words,\"频率\":words_frequency})\n",
    "word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eae6d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#分别用PCA和t-SNE降维看效果\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "#先看PCA的可视化效果\n",
    "X = model.wv[words]\n",
    "pca = PCA(n_components=2)\n",
    "result = pca.fit_transform(X)\n",
    "ig, ax = plt.subplots(figsize=(20, 10))\n",
    "# 绘制散点图，圆圈就是出现的频率\n",
    "ax.scatter(result[:, 0], result[:, 1], c='SeaGreen', s=words_frequency,alpha=0.5)\n",
    "# 不同的圆圈有时会重叠在一起，可以使用adjustText修正文字重叠现象\n",
    "from adjustText import adjust_text\n",
    "new_texts = [plt.text(x, y, text, fontsize=12) for x, y, text in zip(result[:, 0], result[:, 1], words)]\n",
    "adjust_text(new_texts, \n",
    "            only_move={'text': 'x'},\n",
    "            arrowprops=dict(arrowstyle='-', color='grey'))\n",
    "# 美观起见隐藏顶部与右侧边框线\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a48649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "ts =TSNE(2)\n",
    "result2 = ts.fit_transform(X)\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "# 绘制散点图\n",
    "ax.scatter(result2[:, 0], result2[:, 1], c='SeaGreen', s=words_frequency,alpha=0.5)\n",
    "# 使用adjustText修正文字重叠现象\n",
    "new_texts = [plt.text(x, y, text, fontsize=12) for x, y, text in zip(result2[:, 0], result2[:, 1], words)]\n",
    "adjust_text(new_texts, \n",
    "            only_move={'text': 'x'},\n",
    "            arrowprops=dict(arrowstyle='-', color='grey'))\n",
    "# 美观起见隐藏顶部与右侧边框线\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c260244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#进行聚类\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "\n",
    "#用轮廓系数绘制学习曲线找出最优类别数\n",
    "ss = []\n",
    "krange = list(range(2,7))\n",
    "for k in range(2,7):\n",
    "    model = KMeans(n_clusters= k,random_state=0)\n",
    "    model=model.fit(result)\n",
    "    ss.append(silhouette_score(result,model.labels_))\n",
    "plt.plot(krange,ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43e238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#用PCA降维数据后的分类结果\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters= 3,random_state=0,init=\"k-means++\")\n",
    "model = model.fit(result2)              \n",
    "# 将聚类的结果和中心点的结果都画在原图里面\n",
    "plt.scatter(result2[:, 0], result2[:, 1], c = model.labels_,s= words_frequency,alpha=0.5)\n",
    "plt.scatter(model.cluster_centers_[: , 0],model.cluster_centers_[:, 1], color = \"red\") #加上每一个的中心带你\n",
    "\n",
    "new_texts = [plt.text(x, y, text, fontsize=12) for x, y, text in zip(result2[:, 0], result2[:, 1], words)]\n",
    "adjust_text(new_texts, \n",
    "            only_move={'text': 'x'},\n",
    "            arrowprops=dict(arrowstyle='-', color='grey'))\n",
    "\n",
    "# 美观起见隐藏顶部与右侧边框线\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e64b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# 定义KMeans，以及K值\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "# 根据数据data进行聚类，结果存放于result_list中\n",
    "result_list = kmeans.fit_predict(result)\n",
    "# 将原始的数据data和聚类结果result_list\n",
    "# 传入对应的函数计算出该结果下的轮廓系数\n",
    "score = silhouette_score(data, result_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
