鉴于大部分代码，我已经打上注释，这里只说明我遇到的问题

1、本来我是想通过京东在返回信息中的评论链接来获取评论的，但是我经过尝试没办法找到评论的文件所在，经过多方查找，我发现可以通过构造网址对评论进行访问。
京东的评论信息存储在"https://api.m.jd.com/"这个URL中

data中
其中functionId为是否筛选当前商品，我设置一个变量func来处理是否筛选。productId为需要获取的商品的编号，使用str函数进行处理后传入。page为所获取的评论数据的页码使用str函数进行处理后传入。其余参数对获取信息没有什么特别影响，但不能省略。

在京东搜索商品是，url的构成通常是 https://search.jd.com/Search?keyword= +keyword
因此我们可以考虑将前一部分 'https://search.jd.com/Search?keyword=' 固定，然后将输入框的keyword加入url构成一个完整的京东链接 代码实现
前面我们已经成功生成了url，使用get命令可以轻松获得淘宝或者京东网页的数据，当然，前提是需要有一个有效的cookies(在header中修改)
京东返回的是json格式的评论数据
这里就可以使用正常的字典get方法，去查找需要的数据，并将其储存在data文件中
各个参数的作用
"productId": 这个参数指定我们想要获取评论的商品的ID。
"score": 这个参数指定评论的评分。在此例中，这个值是固定的，"0"表示获取所有评分的评论。
"sortType": 该参数用于指定评论的排序类型。"5"表示按照默认排序。
"pageSize": 该参数用于指定每页展示的评论数量。在此例中，每页展示10条评论。
"isShadowSku": 这个参数在此例中被设置为"0"，表示我们不需要获取影子商品的评论（影子商品通常是指商品的副产品或者附件）。
"fold": 该参数在此例中被设置为"1"，表示获取已折叠的评论。
"page": 该参数用于指定我们想要获取的评论页数。上述代码中用循环实现了分页爬取

同时，鉴于现在大部分的电商网站均有反爬虫机制，当然，京东也不例外 
这里我使用time模块和random模块实现对程序的随机暂停，在代码中也有注释体现

而且我通过使用fake_useragent 中的 UserAgent类，实现了每次访问网站，都随机取出一个代理，以此来模仿，人类操作，避免反爬虫触发。



数据整理写在这下面：
数据整理的基本步骤，1查看缺失值，以特定的值去填充，治理我是使用的null进行填充（当然这是在json解析时就完成的操作）
2、去除重复的内容，使用的是drop_duplicates（）函数
3、去除无用项，就比如“未评价的内容”，当然就可以直接使用df.loc【】的条件查询
最后我们将清洗后的文件放在了datas\new_file\file_data.csv中



这里我还增加了一个评论内容的指数计算，分数越高说明，这句话是积极的概率越高。当然这只是个不准确的指数，不能与情感分析出的相提并论，但用来一些简单的分析已经足够。
并将其输出到了datas\new_file\计算后.csv中