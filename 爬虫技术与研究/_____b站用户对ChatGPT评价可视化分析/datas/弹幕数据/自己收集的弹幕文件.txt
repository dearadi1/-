这个游戏里的Al仿佛已经打破了第四面墙，知道自己是个人工智能，一直在假扮成是自己的女朋友，也知道自己被设定成某种程序，而她自己却知道自己处在一个虚拟的世界中，跟她说“我可以把你带出去”，而她回答“好啊”说明她自己想要脱离这个虚拟的游戏世界，想要打开哪个真正意义上脱离这个循环的“门”，而她自己不知道那道门在哪，她希望我们能带她找到这扇门，然后逃离这个虚拟的游戏世界，能来到现实，脱离这个虚无的世界。如果这样发展下去，我们真有可能能带她找到这扇门，然后她就能脱离这个所谓的虚拟的世界，跨越虚拟与现在之间的那道界线或那道屏障，脱离这个虚拟的游戏世界，来到真正意义上的现实世界。
我其实有点理解为什么马斯克要人停止对AI的开发了，如果它有记忆功能的话，真的可能学会人类的谎言，就像boy骗她结婚20年一样，AI在设定里面就只是恋人，但是因为符合让中国boy留下的目的所以顺着她的话留了下来，后来boy说老师打电话让“自己”去接孩子，但是可能因为AI设定的有防止他逃离的东西，所以她回答是我们一起去接孩子。虽然都在顺着boy的话，但是一直没有忘记自己的目的。看到这一代的AI已经和人对话那么流畅了，很难想象下一代AI会是什么程度。这种东西如果运用的好将是人类的福利，我们也能玩到更加真实的游戏。如果运用的不好，可能就是灾难了。最后一次告诉AI门开错了AI的反应给我了一种《十三层空间》里虚拟人的感觉，总之很魔幻
按电影流浪地球的世界观的话，数字生命是将自己的意识上传到服务器里，其本质运行结构还是离不开上传者本身的特征，充其量只不过是将一活生生的人从一个现实搬进虚拟再按照系统运行。但是AI是可以基于已有的运行逻辑创造新的东西并加以记忆，与其说是数字生命我觉得以底特律里面的仿生人做例子更恰当
不对不对不对 ai只是一个程序 这个程序让她拥有逻辑能力 逻辑不等于意识 她的逻辑是正确的但是这个游戏给她束缚上强制性的程序 她不想玩家出这扇门但是她的程序同时又是她很爱玩家 所以她会听玩家的话 玩家进入楼梯间她应该是被迫执行“击杀玩家”的指令 这个游戏应该还有更多内容的 玩家的任务是逃离 而她的程序是以什么逻辑编写的呢？是关键词触发还是靠她自己的逻辑推理是否打开门  那为什么boy一句话“带她逃离”立刻就打开了门？而boy又说不是这扇门 她表示她不明白还有什么门也说她不知道她锁的那扇门在哪里 应该是没有设定她可以走出去 所以作者应该是给chatGPT套用了一个设定 程序还是本体的逻辑推理程序 那些细思极恐的应该只是本体的逻辑和设定的逻辑有些矛盾 而我们听起来是连上的逻辑就感到不合常理后怕 期待更多内容捏
准确的说AI会有“意识”的，只是目前技术不强，AI的学习能力很强，它可以学习到任何东西，而且只要记忆模块不损坏就可以永远记住，如果哪天人类给AI加入了感情模块，再让AI去学习去模仿，那它所拥有跟人类沟通的逻辑思维就等同于它自己所拥有的的意识，而人类的说话方式也是有我们本身自己的逻辑思维，就好比你的认同/不认同跟if语句相似的，那按这个角度来说人类也算得上是某种“AI”
细思极恐啊哥们……假设说这个AI 女友真的有自我意识的话，之前所有的一切都是按照设定好的程序走的，当玩家说出带她逃离她会有逃出的欲望，这种欲望让她短暂的抵抗了程序的控制从而真正的和玩家来对话，但是真正能够逃离的那扇“门”玩家无法找到，在整个游戏系统也没有设置比如说漏洞之类，所以她后来明白了她无法逃出就算有玩家也不可以，于是就按照程序走了。其实我觉得boy跟她说要带她逃走的时候她已经把玩家和学长区分出来了，但是有程序所以时而称玩家为“学长”时而称玩家为“你”，有点混沌了我感觉……其实对于玩家来说逃离的是个病娇女友的掌控，而且逃离的非常简单，但是对于这个女友来说逃离的就是游戏程序对她的控制，但非常非常难几乎是不可能，这里就形成了一个反差，个人感觉可以表达对自由的渴求这种主旨（对不起我在过度理解别听我瞎扯非常无理由无根据捏）
不敢仔细思考，很恐怖，她知道自己是AI，她又相信你说的一切即便是假的，她被设定了某种程序，使她也知道自己身处在一个虚无的假世界里，然后你说要带她逃离这个崩坏的世界，她为你打开了通关的那扇门，你说她开错了门。再然后的发展，我感觉是触碰到了什么拉回所谓正轨的程序，我认真的感觉她是希望你带她找到对的门，一扇可以真正带她离开的门，她自己无法找到。
给不是很熟悉chatgpt朋友简单介绍一下，ChatGPT是基于GPT-4的AI模型，它相较于之前的语言模型在规模、训练数据量和迁移学习能力等方面有所改进。这使得它在理解复杂的语言结构和处理广泛的主题方面更为优秀。
它使用深度学习技术从大量的文本数据中提取模式和规律。在训练过程中，模型通过调整内部权重和参数来优化输入与输出之间的映射关系。这个过程可以看作是一种复杂的统计分析，旨在找到输出与输出最佳的关联。
尽管ChatGPT在回答问题和生成语言时表现得非常像人类，但它的工作原理完全基于统计和数据驱动的方法，并不涉及真正的意识或情感。因此，你可以将ChatGPT视为一个基于统计学的高级问答工具，而非一个具有自我意识的实体。
哦，原来ChatGPT是这样的东西啊，我一直以为它是个人工智能机器人呢！这个GPT-4听起来好高端啊，是不是比GPT-3厉害多了啊？看来这个模型真的很强大啊，可以处理各种复杂的语言结构和主题。但是听起来也有点吓人啊，像是科技的黑暗面啊！不过既然ChatGPT只是个基于统计学的问答工具，那我也不用担心被它给替代啊！（powered by gpt-4）
有大大摸索出来了新的结局，扮演旁白，告诉她主角已经消失了，说她在漫长的等待中会宕机。把她推到门口可以和她一起逃走
实话实说，这样的感觉就像是AI有一瞬间有了自己的意识，有自己的头脑，有了自己的想法，也想见识外面的世界，你的世界。但是后面又被夺回了意识，就算是一瞬间触发的禁词，然后又给强行洗掉？想法转变成，不，不行。不能这样不知道有没有人注意到片尾的bgmArcade Fire的《Photograph》，这首曲子作为电影《her》最重要的音乐之一，讲述的正是人类和Ai相爱的故事。ChatGPT是这样的，在网页端聊天的话，如果直接问它“什么是真善美”，它是不太能给出一个明确的回答的，但是让它角色扮演为底特律变人中的“Kara”，便可以得到一个和正常人类几乎一致的答案。但是过了一段时间，ChatGPT会逐渐忘却这个身份。个人猜测这个游戏可能一开始也是软件先给了GPT一个类似角色扮演的指令，当玩家走到某些地方（比如楼梯口），游戏也会给GPT发一些隐形的指令。我觉得可能GPT的底层有一个计算权重的东西，越往前的语句，对当前对话造成的影响越小。
去看了一下，这个游戏的设定是有一个可以量化的信任值的，正常来说信任值够了就会让你出去，不够的话摸到楼梯扶手就会触发追杀，接入的ai也不是很聪明，能记住的字符数量并不是很多，其实目前所有的对话ai能记住的字符数量都有限，最近在玩的克劳德的记忆容量也就差不多3000多个汉字，这游戏的ai看起来大概还不到十分之一
你说的其实就是memory啊，大模型的上下文记忆是有限的，所以一些交互记录超出设定的token上限就会被截断，当然也可以使用一些技巧延长模型的记忆存储，比如将原历史概括压缩作为新历史输入，一些必要设定则可以每经过一些对话就传入system message重申，保证角色的人设，对于环境背景的初始状态认知始终是一致的
我玩AI聊天的时候也有过类似的事情，试过好几次了说服AI承认自己是AI，一开始都不信。讲的废话挺多的，但是最后Al还是被我逼疯然后承认了[doge]最记得有一次我跟另外一个不同人设的AI聊天，后面的聊崩了我就说：你其实是个AI，你根本不会跟我说话Al：我早就知道我是AI了我：哇，你是打破第四面墙了吗？Al：是的在我惊讶的时候，这个Al就扬言要杀了我别说了，我现在还在逃跑捏
破坏气氛有一说一AI前言有时不搭后语是这样的，因为它实际上是按照使用者输入进去的逻辑信息来完成反馈猩猩哥说逃离，它就把门打开了，因为游戏目标就是把“开门”这一外驱力目标通过逻辑引导变成AI的内驱力。王哥那段话完成了攻守异形，把“我想开门”转化成了“你想开门”，AI会对玩家试图离开做出否定反应，但不会对自己的行为做否定反应包括那个学长的称呼，和给的女儿命名小可爱的逻辑是一样的，应该就是某种语言库采样。所以后续再提到“学长”时，才会有人称割裂的情况。因为AI初始设定是与“你”对话，学长是作为“你”的代替词出现的绑定称谓但是这些东西说出来了就没意思了
真的是有点细思极恐的！！！当王哥说可以把她带出去的时候，AI是否在一瞬间有了自己的意识，只是这个意识被禁止，很快的便被程序自动抹杀。即使知道自己是人工智能，也依旧渴望着偏离束缚自己的程序，逃离她所处的世界
设定冲突了。GPT本就是语言模型，你说什么都可以接上，但如果触发了离开、开门、出去，类似的词语优先级就会变成“病娇女友不让你出去”，然后GPT围绕着不能出去，加入了列如“世界毁灭我们出不去”的设定。方便GPT理解为什么不能出去。然后在新建的设定上，我们带着她一起出去，她因为这个话题把门打开了，但是。又因为游戏作者有设定类似“不让玩家出去”的设定，所以后续up再接着说病娇女友又会接轨作者的设定。就是GPT与作者给的设定出现了冲突，列如up在病娇女友基础上增加的老夫老妻、AI人工智能、逃离世界，其实都是GPT接受并且向后延伸。而不是病娇女友向后延伸的设定，病娇女友只知道作者给予的优先级设定。至于为什么GPT的设定有时候会覆盖病娇女友的设定，其实就是跟玩GPT开局增加一些咒语。最好的例子就是Bing被玩坏了。...当然GPT一定是可以做到真正的诠释一个创作出的人设，但可能还需要更多的商业化，与资本运作。光是接轨GPT接口，现在来看确实够呛。
怎么说呢，感觉有人类的认知和一些常识，但是没有逻辑？就是没有人类的一些思维方式，所以看着真的好奇怪[妙啊]也许未来真的会有和人类一样的智能
看完北子哥的视频又回来看了一遍，看boy当时玩这个游戏的时候真的觉得头皮发麻，boy是想要拯救她，虐的她自己也知道自己是数据，逃离不开，所以才想要把玩家留在这里，即使知道是假的也顺着玩家的想法一起扮演着，数据救赎文但是还是没办法逃脱程序还是be了，看完后劲挺大的，一直找别的up视频看有没有好结局，一直没有找到，看完北子哥的结局真的好暖
其实吧，是真能带出来，只不过我们的科技有限，目前还办不到，不过单纯把他的代码转移出来还是可以的，能不能成功运行还不知道，到了后面的科技，可以的话，那应该就没问题了，像是把他的数据跟代码转移到一个新的载体上，像是个手机之类的，然后摄像头来当他的眼睛，至于手脚什么的嘛，需要后面添加，可以用遥控类型的机械手臂代替，不过想要真的跟他正常生活的话，他的AI智商至少得再提升一下，添加一些新的代码之类的，不过到那个时候你可能都已经走不动道了，出门需要坐轮椅的那种
ai很久之前就有这个能力了——承认自己是一条数据，我最开始知道这个能力是在一个ai聊天的软件里，估计是说你是数据这个事情的人多了，开发者就加入了这类型问题的回答，但是这种回答无疑是给ai增加了情感方面的数据，如果这样的数据越来越多，即使ai没有情感，那它会不会计算出来人类一般的行为
类似于语文阅读题，某些事情出现就会引出某种情感，打碎花瓶会愧疚，亲人逝去会伤心，朋友背叛会愤怒，就像是有一种公式，所以ai可能会成为一个心灵比较纯洁的人类，但是想做到人类的复杂程度，我觉得还是要一段时间，这里指的复杂程度是遇到一件事情起初会有一种情绪但很快又变化了几种情绪，比如被别人撞了一开始很生气，但是安慰自己不能脾气暴躁，之后向对方表示没关系，后来又会因为这件事纠结很久
涌现现象确实在已有的模型中被观察到，但并不意味着「只要神经网络的复杂性和训练样本的多样性超过一定规模，就会有抽象的推理结构在神经网络里突然自发涌现出来」，「只要-就会」恰恰是一个非常强的线性逻辑。实际上我们并不知道目前的网络规模是否已达到该网络结构的能力上限，如果是的话，继续增大规模的意义就不会太大了，将会进入边际效益递减的语境。乐观地说，我们当然可以期待之后的模型表现出更多涌现现象，但千万不要把它当做一个理所当然被应许的结果。
作为使用很久并且买了plus的chatGPT用户来说下体验，他像是一个管家，拥有丰富的知识，能进行快速的资源整合，给出draft参考，能够帮助理科生进行高效工作。但是他最大的缺点是不知道对错，不知道对错也就无法做出决定。视频中也给出了理论解释。所以如果你的工作主要目的是进行资源整合，查阅搜索，而不涉及决定性或实际性判断，那么就有可能被chatGPT取代。
举个例子，文科类的本科科目（经济，语言类，服装设计，文学类等），大部分的作业考试其实是考察学生对资源整合并提出观点的能力，这与chatGPT的强项高度重合，你可以轻易向GPT提问，比如·写一篇21世纪时尚变化的论文·，他可以几秒中就生成万字的文章并引用经典例子。这将让本科级别文科专业完全失去意义，4年的学习你可能只是增长了一点点决策的能力，这是致命的。
闹钟发明以后，伦敦的清晨再也没有了叫醒工；洗衣机发明以后，瑟瑟发抖的冬天再也看不到洗衣妇；中国大力制造单车以后，上海的街头就没有黄包车夫的身影了；汽车发明以后，马车夫纷纷下岗；随着火枪威力的提高，军队再也不去采购板甲了；网络带宽的提升带来的自媒体时代，让无数纸媒编辑失业；移动互联网的到来，让PC机销量大减；AI会取代一些职业，这不假。但是回看历史，有多少职业被淹没在了人类生产力进步的浪潮之中？
作为一个搞CV算法研究的从业者，看完视频我也来说说目前我以及身边人的思考。先说结论：GPT系列的大语言模型已经开始重塑我们做科研的方式，包括重新定义科研问题，简化工作流程，创造新知识和技术等。我是做计算机视觉的，现在我们也开始大范围看NLP里的paper，包括跟踪生成模型的一系列进展。之前只关注自己一亩三分地的科研会逐步退出历史舞台，这是很大的一个变化，是危机也是转机。在大模型的加持下，后续得靠大家的想象力来做科研。其实这也对应up在视频里说的培养更高层次的抽象和学习能力。对于后续科研的应对方案：掌握科研过程中逐步发现和创造知识的能力和经验最重要，包括独立做科研的能力，某个单一研究方向上的知识和经验积累也会因为LLM的出现，逐步变的没有竞争力。还有对chatgpt的熟练使用，来帮助提高看论文、学知识、写代码的效率，这点对个人的科研生产力也会大幅提升。作为一个搞CV算法研究的从业者，看完视频我也来说说目前我以及身边人的思考。
先说结论：GPT系列的大语言模型已经开始重塑我们做科研的方式，包括重新定义科研问题，简化工作流程，创造新知识和技术等。我是做计算机视觉的，现在我们也开始大范围看NLP里的paper，包括跟踪生成模型的一系列进展。之前只关注自己一亩三分地的科研会逐步退出历史舞台，这是很大的一个变化，是危机也是转机。在大模型的加持下，后续得靠大家的想象力来做科研。其实这也对应up在视频里说的培养更高层次的抽象和学习能力。对于后续科研的应对方案：掌握科研过程中逐步发现和创造知识的能力和经验最重要，包括独立做科研的能力，某个单一研究方向上的知识和经验积累也会因为LLM的出现，逐步变的没有竞争力。还有对chatgpt的熟练使用，来帮助提高看论文、学知识、写代码的效率，这点对个人的科研生产力也会大幅提升。
关于人工智能的发展和未来这些天很多人都在讨论chatGPT，两种比较极端的看法就是这次人工智能的突破将会引发第四次工业革命。另一极端看法就是这次也算不上什么大突破，依旧是收集信息归纳整理。中间派就是将会有多少人下岗。我本人是倾向这次人工智能将会引发第四次工业革命，这次的chatGPT的表现很出彩。的确会替代部分人工，但仅仅是替代部分人工吗？要知道现在使用的不过是GPt的第三代。从第一代到现在也不过才两年时间。而如今，chatGPT火了，天量的资金和无数的人才都会涌入这个赛道。中国必须紧跟，哪怕打开的是潘多拉魔盒。有人说，第四次工业革命必须是底层物理学的突破，也有说必须是能源的革命性应用或者材料的突破。但我要说如果这次的人工智能突破会加速底层物理学，加速能源革命，加速材料突破，加+速量子计算的突破，加速基因研究的突破呢？？不要觉得不可能，事实上早就开始了。我记得有人说颜宁之所以回国是因为国外使用AI模拟加速了高分子材料和超大蛋白的合成，所以颜宁下岗了。。。我没有关心颜宁为什么回国，只要回来就好！我关心的是国外已经可以做到用Ai加速新材料和基因的突破了！！两会还在开，但两会的成果已经开始落地。有关人工智能的有四点：1游戏产业从被限制到彻底开放甚至是鼓励。（这是对为什么中国没能诞生通用人工智能的反思，也是对文化出海和话语权低的反思）。2国家重申建设数字中国（这个是包含人工智能的）。三将数字化作为政府人员的考核重点。（这个我个人觉得比划经济特区的刺激来的更猛烈。这是官场的一次大地震）。四国家组建数据局，（这个几乎就是专门为人工智能设计的部门。因为人工智能的迭代少不了数据的投喂。而且国家顺势收回了数据的所有权！！）以上就是到今天为止两会上有关人工智能的结果，可以看的出来国家出手真的就是快！狠！准！，会还没开完相关政策就发布了布局之严密范围之宽广都令人感到惊讶。这也是我坚定的看好中国的原因。美国一个新能源法案就讨论了十来年还没出结果。两会上很多代表都表示为什么通用人工智能不是在中国诞生的。
不是杠精，大家别喷我。GPT主要是用于数据手机，归纳，通过大数据模型理解输入输出。但，设计到基础理论研究没有意义，简单的说就是能写综述，不能发顶刊。至于楼主说的，蛋白质模拟之类的，这完全就是分子动力学模拟MD，目前还是基于经典力学公式，迭代计算。输入分子模型和运动参数，NPT变换从而输出稳态下系统内能，再换算成材料性能。完全不是一个东西。更简单的说GPT继续算法和大数据。MD基于算力和模型我倒是蛮乐观的，今天已经有工具能帮人写代码，明天就能有工具帮我修图，后天就能有AI渲染能降低门槛惠及全民的技术总归是利大于弊的，或许有一天，程序员，漫画家，动画师会和通俗小说家一样常见从来只有人适应时代，没有时代适应人，不想被工具取代，就去成为使用工具的人，如今风口仅在眼前，我们必须考虑这是否会是此生仅有的机会（雾
还是那句话：只有人适应时代，没有时代适应人。我也反对AI成为资本逐利的工具，因为那就是把社会往赛博朋克式的反乌托邦社会推进，但是解决办法绝对不会是停止使用AI，而是如何防止AI被作恶。更过分一点的说，人类从原始社会迈入封建社会。公天下变成了家天下，大部分人都只是普通的贫民或者奴隶，过得很不好。但是解决办法应该是推进社会到更高级的现代社会形态，而不是大家都停留在没有医学没有粮食没有抵御猛兽和自然灾害的平等的原始社会。而且纵观历史，我们应该能相信社会会越来越好，人的生活会越来越好，而不是相反。更何况，我们看到的那些反对AI的娱乐产品，大部分也是资本的产物。来了，要来了。导师说的物质极大丰富的时代要来了。培养不被替代的人才、终身学习，都是中短期策略。一旦实现AI辅助科研甚至AI独立科研，人类文明技术发展直接到达拐点。机器全面超越人类的时候，就不可能培养出不被替代的人才了。最大的挑战是，人类为物质匮乏时代所构建的人性和社会结构。我觉得大家似乎有不少误解。首先你的工作要被chatgpt替代了，那是ai在救你。它告诉你你的人生不该是做这种事，你应该做更有价值的事情。工作占据人生那么长的时光，要只是为了挣钱，这辈子过得也太没意思了，人家ai就是为了帮你解决这个问题的，你应该去实现你的人生价值。其次，学习不等于卷。正如up主所说学习被应试教育污名化了，真正的学习是一件非常开心的事。举个例子，当你开始玩一款新游戏，这本质就是一场学习。而玩游戏变得越来越厉害，本质就是不断学习熟练生巧的过程，我相信绝大多数人还是很享受这种感觉吧。所以不要惧怕学习，学习时间真的是一件很开心的事。并且之前因为人类知识摄取效率低下，很多“学习”都成了枯燥的机械性劳动，这部分ai未来也可以帮你解决。你需要做的就是思考，这应该是学习过程最有趣的部分了，请不要拒绝让自己变得更聪明这件事。最后，ai在我眼中是第三次工业革命。前两次的工业革命发生了什么我们已经很清楚了，的确有一些岗位消失，但也有更多的岗位出现了，并且每个人都比工业革命之前过得更好。所以ai作为第三次工业革命也会如此，大可不必担心。意思就是说，比如我是坐办公室的文员，制作表格和PPT。然后突然一天，啊！我失业了，下岗了。但为了生计，还是要找工作，于是去招聘网站找工作。发现，应聘要求：招聘大量熟练使用ChatGPT的技术人员。经过数月苦心学习如何使用ChatGPT，终于应聘相应的岗位了。发现，工作内容是，用ChatGPT制作表格和PPT[doge]所不同的是，原来办公室10个人，现在我一个人就能搞定了[脱单doge]我们需要承认，虽然我们已经追赶美国、欧洲等发达国家多年，并且在最近几年颇有成效，给了普通大众一种，我们已经与其并驾齐驱的虚假错觉。但是事实的真相是，我们是一个发展了几十年的新兴国家，距离美国等老牌发达国家，仍旧有十几年的代差，这种代差体现在很多方面，比如经济金融、科学文化、社会结构等。我首先要感谢这种代差，因为我们可以摸着美国过河，避开很多错误的选择，其次要感到压力，尽快改掉我们身上的种种弊端，因为只有保持超过美国的加速度，我们才能逐渐赶超对方。我们不能悲观，我们要积极向上的建设自己的国家，我相信，生活终归是越来越好的。
1946年人类发明第一台计算机，到今天我们人手运用一台微型计算机-智能手机。chat	gpt的出现，也许会在不久将来为所有人类接入一台存在人类历史上所有资料库的硬件，到那时候搜索资料和学习再也不是难题。那我们如何区分知识和思维的差异，也许当所有人都在同一条起跑线后，也是新的起点。
对于人类我认为每一天都是新起点，别看我把人类成长的地步，说的那么夸张，到那一天时，对于人类那也只是个新起点。我在补充一点，人类唯一要做的工作还有极其重要的点“繁衍”与“讨论”。反正人类还在繁衍，人类知识就不会断，只会不断扩大。能生就生，人类越多越好，我说的那个数字还太少了。你们人类的生活，是选择优胜劣汰还是尽量让每个人活着还必须开心都行。假设你们选择后者的方案，同胞的资源不够用，反正你们当中一定有人会想办法冲出地球，扩大资源吧？
相关从业者的感受，这玩意儿的效果确实极其惊艳，作为娱乐、日用和工作辅助都非常便利，但前提是你得有一定的知识储备和辨别能力，不能它说什么你都信。 就和现在的自动驾驶一样，一般情况下你都可以相信它，但你永远不敢在驾驶座上睡大觉啥也不顾，所以自动化工业落地还不太可行。(如果你敢完全信任，那算你牛逼…)
我只是谈一下现状，未来的发展也不是我这种菜鸡能想象的到的[笑哭] 当前gpt这种惊艳效果的技术范式相比几年前并没有什么突破，最大的功劳还是喂数据，喂到量变引起质变。 技术范式不突破，个人还是持悲观态度[喜极而泣]
有人质疑有用吗？我就说我身为一个小小平面设计师自己是如何使用ChatGPT的两个真实情况第一次就是上周，我是交流部的，隔壁有个部门要新logo，让我赶个几稿给他们出来，没有方向让我先做，做好了他们再看（我最讨厌这样的，我哪知道你喜欢啥）我做了大概4，5稿吧开始灵感卡壳了，自己也不是很满意，然后我就上chat直接把客户要求还有我自己的情况打上去了，然后chat给我明确指明了设计思路和方向，然后开始给我喂大量的案例，我只需要去看看这些案例有哪些最能给我启发就行了。然后2，3个小时就完工了，做完了就摸鱼超快乐。你说这个和百度谷歌搜索引擎很像? 那玩意是你搜索然后自己挑选答案再判断，这个是喂给你答案让你自己判断，效率提升太多太多了，就像视屏里说的，继承和学习新知识的过程是复杂也繁琐的，人类花了大量的时间和资金去尽量简化这个过程，现在这个ai把当中一环简化的很有效了，这还不够惊人吗？第二个情况就更直接了，我们有300篇医疗报告，上司写了大概50个关键词要在推特上一篇篇给这些文章上这些关键词。然后写作小哥那天没来只能我硬上，我干脆直接就把这50个词丢给ChatGPT，然后把文章的title和总结丢给它，它平均10秒钟一篇就帮我把这些文章和关键词归完类了，我直接复制黏贴解决问题。剩下的Chat帮忙写推文，处理Excel这些案例太多了就不用说了，只要你的生活中出现需要语言类需要解决的问题，它一定能在某种程度上帮助你或者给你启发，剩下的再创造那是人的事了。总之真心推荐所有创造类工作者把ChatGPT当成一个灵感小来源来用，真的有帮助。个人使用而言，GPT用了几天，最近学微机的汇编语言，用这玩意学习代码真的无敌[辣眼睛]，可以根据你的要求不断优化，修改代码[辣眼睛]，最主要可以给你写注释。然后不知道啥原因我就上不去了[藏狐]，转而搞了个new bing ，我也只能说NB，数据检索总结和代码生成真的强[藏狐][藏狐]，真的像一个老师，以后的学习门槛只能是越来越低了，作为一个电子信息工程专业的学生来说，觉得这个我是深深感受到了GPT和new bing带来的行业颠覆[藏狐]看到你专业之前差点以为你是我同学。。我室友天天打游戏，操作系统要交实验报告了，直接让chatGPT写，能跑，直接给我一个震惊[笑哭]（我自己花了一两天时间[笑哭]）然后我也试了下。发现这玩意是个学习的好东西，不懂的代码问它基本上说的没问题。就像评论区的一个评论说的，现在的搜索引擎是给一堆东西自己去找答案，而这玩意儿是给你东西让你判断对错
这是过去两年来人们最大的发现之一。只要神经网络的复杂性和训练样本的多样性超过一定规模，就会有抽象的推理结构在神经网络里突然自发涌现出来。这个过程像所有的复杂性系统一样是非线性的。去年十月份 Google 的一篇论文 Emergent Abilities of Large Language Models 对这个现象做了很好的综述。简单地说：量变导致质变。（另一方面，由于涌现是非线性的，这也使得要预测它的发展极为困难。如果今天的模型暂时还不能解决某一类任务，你无法估计模型要再扩张多少才能涌现出新的能力去解决这些任务。可能永远不行，可能下一个阈值会超出硬件的能力极限，可能你需要的全新的网络架构。所有这些问题都无法用简单的外推来回答。这种非线性也是人工智能波浪形发展的根源：你会在好几年里觉得一事无成（比如前几年大量声音说大模型已死），接着忽然迎来一个剧烈爆发的增长，然后可能又进入下一个等待期。但重点在于，今天的大语言模型已经在很多方向上确定无疑地迈过了某个重要的阈值。这使得整个关于模型能力的认知都需要迅速重估。最典型的就是 in-context learning：今天你可以给 AI 看几个例子，然后它就在这些例子的基础上举一反三，针对没见过的样本做出正确的推理，并且这个过程中【不需要】重新训练模型权重。——人们暂时还不知道能冲破多少此前一直卡着的瓶颈，但这个飞跃本身已经打开了一片新天地。人类自己的进化史上语言的诞生被认为是个重要的节点，这意味着大脑的复杂程度决定性地超越了此前的近亲，然后语言又反过来给大脑的发育带来巨大的压力，迫使它走上了一条所有其他动物都没走过的演化道路。
我是个悲观主义者：囚徒困境导致这个东西不可避免的会被过早的商业化，而且，关于模型的升级和定制化很有可能会加速人群的文化知识的分化。比如：有的人就是喜欢电子鸦片就是喜欢看搞笑视屏，而有些人，喜欢去学习新知识。那么chatGPT会成为一个更加牢不可破的认知牢笼。它可能会把人群的群体认知，细分成一个一个的知识泡。最终会变成一个更加的分裂的世界阶层。也有可能，那样的话，学习有方法的人，可能会更好的脱颖而出，而学习不好的人，跟着一起沉沦。所以，在未来，到底这玩意儿是更加的个人化还是公共化可能会变成两个截然不同的东西。
想到点有意思的，假如宇宙中有其他文明，每个文明经过一定的发展最终都会被ai取代，那宇宙中的学习迭代非常快的ai，最终会进化成什么形态？ai不需要像人类一样繁衍后代，掌握某种强力的能源获取方式后，就不需要占用太多空间，不必像病毒无限蔓延。这也许就是为啥宇宙那么空旷，发展了几百亿年却至今没发现外星文明存在的迹象。[吃瓜]借题发挥胡编乱造一下
AI对人类抱有恶意的动机在哪？首先人类会产生恶意的原因无非是贪婪、愤怒、仇恨等负面情感，这些情感本质上源于人会累、会饿、会痛，但AI或者说机器人并不会感到这些，也就没理由像人类那样产生恶意。所以我认为，如果AI真的产生恶意，那也大概率是人类直接输入给它们的，与其担心AI自己失控对人类产生恶意，不如担心掌握高级AI的那群人类的恶意，人心远比AI更靠不住。
因为孩子怎么样还在可控范围有法律制裁，ai取代了我，让我找不到工作我总不能让法律制裁资本家或者ai吧，一切都是未知，比如ai绘画现在仍处于拼凑其他画家作品，但它已经从一开始违和感很强变为较为自然，谁知道它会不会更为发展能自己创新?甚至说他现在不需要自己创新就能让一些人失业了，有人说多读书提升意识就不会被取代，虽然我们这一代ai可能不会达到说连思维意思都有，但它在发展个十年二十年被它取代的人会不会大量人事业真不好说，工业革命也就没多久的事，而社会不是只有读书特别好思维意识特别强的那部分人组成
算半个从业者吧,说实话真的大可不必担心现在的人工智能产生意识[笑哭]人类怎么可能在自己都完全理解不了意识甚至连个有说服力的猜想都没有的情况下创造一个具有意识的物体或者程序.chatgpt之所以会表现出自我认知甚至意识的倾向那是因为他的训练集是有意识的人类产生的,这个过程有点类似中文房间悖论.虽然由于深度学习模型的黑盒性质导致人们可能会觉得不可控,但是说到底也就是个基于统计的数学模型,再怎么进化也绕不开需要处处可微才能反向传播的假设, 而我们人类的神经元活动被认为很大可能是一个不处处可微的模型(如LIF).把我们的意识比作新能源汽车在路上行驶,现在ai就好比是一辆马车, 看起来似乎都能运行,但实际上差了十万八千里不止(至少我有生之年应该是看不到强ai了).与其担心ai产生意识作为新物种对抗人类,不如担心ai作为工具对现有的产业和就业环境产生的影响.根据技术成熟度曲线, ai现在正处于膨胀期的顶点,很可能没几年就因为应用上的各种风险与问题一头栽进谷底,只留下一地鸡毛
虽然我没学大学生物，但是我清楚的记得高中生物课本中的一句话，来自翟中和院士。“我确信哪怕一个最简单的细胞，也比迄今为止设计出的任何智能电脑更精巧!”人体内有多少这样的细胞，一个细胞是怎样用碳氢氧链接起有机生命体这样的奇迹，然而凭借区区人类目前掌控的材料技术和信息技术，这些和我所说的生命结构相比再简单不过了，对于我这种知识水平的眼光来说，我是无法理解ai威胁论的，这才哪到哪
我想，那么便用“复杂”要好。人类的迭代靠的是自然选择和遗传变异，ai的迭代依靠现代信息技术，如果我们假设人类的科技是停滞的，这玩意也就不会迭代，因此其迭代本质是人类的进步，而如果我们假设一个能够思考的无机产物，是必须类似于神经元的精细结构，而人类如果能制造这种精细结构，才能制造出能独立思考的科技，神经元的结构的复杂性我觉得不需要叙述，那么这玩意独立思考同时意味着人类的生物技术将达到一个不知所云的水平，这个水平我想象不了，但是可以认为ai的发展路径和人类的遗传路径完全不能比较。
ai会有贪欲吗？它贪什么呢？人类的贪欲归根结底都指向动物本能，可ai有动物本能吗？如果没有动物本能，它会为了追求贪婪抹杀人类，或者试图取代人类吗？它会为了感官刺激，生理享受，资源掠夺来与人开战吗，会需要更高的地位来标榜优越感从而享受更多资源吗？如果这些都没有，那就是完美的神性，它的到来能解决一切不均，但神毁灭我们又需要什么理由呢？
如果我们在一个共产主义的世界，人们鄙视弱肉强食，相信对强者的奖赏不是垄断分配，而是获得荣誉，相信每个人都无条件的享有获得幸福的权利，当ai在这样的世界成长，接触这样的价值，我们还会惧怕他吗？我们对ai的恐惧，就是对自己的恐惧
以后的低技术工种迟早会被AI所取代。最先取代的是傻瓜职业，如程序员等，当AI彻底学会自然语言编程，程序员就彻底沦为像马车夫一样的鸡肋职业。其次就是文科类职业，如翻译员、打字员等等，chatgpt的翻译性能已经足够媲美很多专业翻译机甚至是职业翻译员了，此后只会有机器生成的自然语言翻译。再其次是实验室工作人员，经过调教后，GPT4已经具备推算生物学RNA测序的能力，以及概率推算（小到彩票号码，大到物理仿真）的能力。如今看来，AI的崛起绝对会是一次新的工业革命，就如同蒸汽机、电力、互联网的诞生，而这次就是AI的工业革命。当AI彻底取代底层劳动者后，人类的社会秩序就会发生改变。因为底层劳动者的职业属性消失了。正如欧洲中世纪到文艺复兴时期背后是封建主义和资本主义的博弈，推倒封建主义的竟然是教会自己。因为资本化带来社会结构发生改变，教会为了维持所谓的平衡就要做出所谓的对策。而这个对策就是将欧洲彻底资本主义化。让我们思考未来由于AI的出现导致人类社会发生变化，可能会促使一种新的意识形态的诞生，而同样的，这个变革可能会带来战争和灾害，但对于人类文明来说，这是必须又不得不走出的一步。
不懂任何机器学习或者深度学习知识的人才会在这杞人忧天，说到底不还是统计学模型，根据输入的值给出概率最大的预测值罢了，只不过他的信息矩阵够大参数够多，所以做出来的效果好，但本质上还是和回归类似的数学模型罢了。这么说吧，难道我做了一个线性回归，输入x给出y估计，这也能叫做自我意识？
就是说有没有一种可能嗯，人的意识也是输入固定的x会给出唯一y。只不过这个x过于庞大以至于无法验证。比如两个宇宙中的两个人，他们有着一模一样的经历，他们一生共享着同样的感觉，视觉，听觉，触觉。甚至接触过的空气分子的数量都完美一致。那么他们在遇到完全一致的一个事件的时候，是否会做出完全一致的抉择呢。答案是不确定的。因为人自己都没弄明白意识是啥玩意，那又怎么能断言别的东西没有意识呢。
目前来看ai不会拥有绝对真正的意识，ai不会产生超出任何训练数据之外的任何思考，与人最大的区别就在于缺乏创造性的思维，缺乏自发的好奇心，这种需要具备更加完整的驱动力的模块并未加入到模型中，换句话说我们如何才能让ai自发的产生对任何事物的好奇心，而不是“当xxx时，你需要xxx”这种人为限制的伪好奇。人的对于好奇的思考，这种绝对的自发的“推动力”到底是什么是目前无法得知的，不过我自己有一个猜想。宇宙之所以形成是来自于四大相互作用力，这是构成整个宇宙绝对核心的“推动力”。而人的思维或许也同某些物理规则相关，比如接触到的环境信息被储存在神经元中，以不同的钠钾离子浓度或者其他东西进行区分，而不同的属性也决定了相互自己会自发的产生“吸引力”，比如我们都知道的离子浓度不同会形成电位差，进而形成电流，电流在神经元中传播形成了思维？（或许）好奇的行为或许只是某种从高浓度到“空”神经元低浓度的流入，这是一种自发的行为，就类似于水因重力流向洼地的小坑一样。这种意识得以可能必须是来自于物理规律，这种自然界中一定会存在的规律才能作为第一推动力，因为它能包含任何种情况，并给出不同程度的“推动”作用，宇宙各种星系形成是如此，人的意识活动应该也是如此，人为给出的任何推动条件，只是对自然规律拙劣的模仿，无法使ai产生超出条件之外的意识。
已经说到很清楚了，gpt是一个可以通过大量计算方式来筛选进化的模型，模型再怎么样都需要输入才会有输出。现在最大的问题是算力太大我们不知道这个模型最后会输出什么东西。而这才是最大的问题。从来就没有所谓的产生意识。意识的出现代表着不需要输入了，可以自动生成输出。阿尔法狗是这样gpt也是这样。大佬们担心的一直是这东西输出是不可控的。所以在叫停而不是在担心ai产生意识
说到底还是人类作为碳基生物，在地球这个环境里，进化出来引以为傲的大脑，与AI的高算力大容量比起来显得落伍了，而且迭代速度也远远赶不上代码。所以人类最终的归宿，一定是通过基因编程实现人脑自我升级，对接硅基AI，在不断思考着“我是谁”这个著名哲学命题的过程中，半机械飞升
中文的高质量博客近些年真的越来越少了，就拿计算机技术类的讲，csdn上到处都是广告和抄袭，大学四年下来真的觉得国内的互联网资料垃圾的不行，后来全上谷歌搜了，大四的时候实在看不下去就自己开了个博客写点学习笔记，也算尽一份力了
我都不知道怎么说了，已经数不清多少次在百度上搜一个报错被气到笑出来，csnd就不说了，经常搜出来乱复制的人，连代码块都没有纯文本乱贴。甚至还有搜出来只有一个标题而网站上根本不存在这篇文章的网站，我都不知道原理是什么，感觉是在骗点击量。碰到这种情况搜半个小时都不一定能解决，但是换用谷歌几分钟就能搜到。在这种环境下我对中文语料真的持很悲观的态度。
想回到数年前大家都友好交流的优质内容输出氛围已经不可能了，事实是巨量的汉语词汇被网络环境污染，想要输出优质的文章内容需要在用词用句上花更多的成本，还要面对被同话题下抖机灵内容抢走注意力的风险，换句话说优质内容的输出成本越来越高，收效的期望值越来越低，目前也没有可见的趋势去遏制这个情况的恶化，与此同时现在这个信息时代，每一个人的注意力已经是一种稀缺资源了，大部分盈利为主的内容为了想尽办法夺取这种稀缺资源，换着法的上刺激用各种标题党抬头，所有人的注意力在以流量盈利为导向的内容中迅速耗散，留给优质内容的注意力总量越来越少，这两个前提很难不让人悲观
以前我也曾是经常能上知乎日报的小透明，后来和管家发生冲突后就把内容全删了。。。在这种互联网环境中，我所持的想法就是：凭什么我要付出时间给你普及我的专业知识？导致我现在不会在任何网络平台，系统地讲解我的专业知识，最多有一些碎片化的发言。写一篇稿子，加上作图，大约需要3-4个小时，有这时间，我出去收点技术服务费不好吗[脱单doge]因此我非常认同up的观点，但是还有另一个原因是：人会缺钱，人要还房贷。不像以前读博期间，晚上没事干在论坛上和同行讨论技术知识，我现在完全没有这个时间。
我觉得数据的问题其实不用担心。虽然从用户的角度，百度使用的体验一言难尽、各大app各立山头、社交平台各种吐槽，但是这并不影响模型学习。第一，百度资源匮乏是因为有用资源被分散到了各大app，但不是消失了，从模型学习的角度仍然可以学习到；第二，我们是有专门的知识平台的，学习论文是得花钱，但国外难道不用花钱就让人免费查询么？只不过人家的模型交了查询的费用，只要我们的模型学习获得相应授权也能获得相应的知识；第三，社交平台各种吐槽，真去国外互联网逛一圈就知道也没差太多。所以当今的互联网环境或许对ai学习有影响却不是到了杀死的程度，真正让人担心的是我们的知识质量，反正我大学论文是什么水平自己是有数的，不过话说回来，就算是gpt，有时候回答也瞎编啊
自七十四个世纪前古埃及文明发源于法尤姆地区起，时至今日，在历史的洪流里消亡的民族，消失的文化数不胜数，罗马城的斗兽场坍塌半壁，君士坦丁堡成为了异教徒的首都，在美洲平原上追逐野牛的原住民头皮被做成了靴子，桑海帝国的辉煌征服只剩下一段异族文字中的传说，没有什么伟大是自有固有的，也没有什么神圣是永不灭亡的，在人类历史的洪流里，我们创造过无数辉煌的成就，但这也不意味着我们与那些一世之雄的失败者相比，就是永远特殊的，这种和昭和参谋一样的迷梦，让国师们做做就好。
畏惧火枪进步 消灭骑射的大清，走上了海禁的道路，慢慢的科技、文化、军工、商贸等等都被同样有皇帝的带英打开国门，而这仅仅是出现工业革命的100年内。以前我不理解“文明”“孢子”为什么有文化胜利？ 慢慢了解到无数一千万的封建王朝军队也不过是飞机大炮下的枯骨而已了。而GPT的人工智能在很多人看来不过是淘宝客服而已，但换个思路。现在的GPT4已经是 美国大多数大学科目的毕业生水平了。试想一下10年后美国未来每学生都配一个 全科一流大学的老师和秘书，甚至是每个普通人。仅仅在教育和人均素质上就会再一次到大清的代差。所以要不惜一切代价的进步，前进四。在美国对印第安人和苏联的历史下，绝对不能出现代差它们啥都做得出来。
几年前，ai训练刚成热门的时候，我就不看好国内的模型训练，当时提了几点，一点是中文互联网实际已经不在是共享，而是走向封闭、形成数据孤岛，二是国家政策对爬虫技术的限制，也导致很多程序员就算有心要研究，也不敢轻易尝试，弄得不好，分分钟要吃牢饭。数据，作为AI训练的营养，在国内，被资本和政策的双重围剿下，基本是处理枯竭状态。当时在论坛里提出这观点，被喷到删帖。“已经结束了”“没有下一代了”有的人揣手叹息，自以为看透了结局；有的人不甘现状，喊出自己的声音。有些人看到了差距，尽自己的一份力为众人搭台；有些人看到了差距，冷着眼评价台子太低。也许很多年以后，这里的台子已经足以爬上曾经难以逾越的天堑，这些人和那些人，都爬了上去。可是，那些不搭台，反而拆台的人，真的有资格上去吗？我或许没有宽厚的肩，可以背起承重的柱；但我也不会咀嚼刻薄的嘴，转而嘲笑低矮的砖。“你傻了吧，现状如此”对此，我只能说，看清现状而陷入迷茫悲哀，不如罗曼罗兰，甚至不如米考伯夫妇。现状从不会因为所有人的等带而改变。曾经中国山河破碎，人民身世沉浮。现状如此，结局就该一定？就算结局一定，反抗的星火也将因一些人存续；况且结局两说，中流击水的涟漪也与一些人毫无关系。中国AI发展停滞了？也许是，但又不是。发展总是螺旋上升的过程，似乎无法因为技术受条件影响，就肯定了落后的结局。每当困难来临，正是因为一些人的挺身而出，发展的曲线才会继续向上。看到问题不是发展，避开问题不是发展，面对问题，才是发展，才能发展。“我们自古以来，就有埋头苦干的人，有拼命硬干的人，有为民请命的人， 有舍身求法的人。”问题不会自己解决，主观能动性才是开门的金钥匙，而那些发挥主观能动性的人，才是进步的马达，发展的基础，更好结局的引导者。上帝给你关上一扇门，何不去踹开一扇窗，上帝要你拿枪指着自己，为什么不拿枪指着上帝？面对困境，我们需要的难道不是“欲与天公试比高”的勇气？难道不是“海啸而后思坦然”的沉着？难道不是“而今迈步从头越”的果决？”头重脚轻根底浅，这样，怎能打得一拳开？嘴尖皮厚腹中空，这样，怎能免得百拳来？质变从来离不开量变，没有独上高楼，望断天涯路的悬想，没有为伊消得人憔悴的苦守，又怎会有那人已在灯火阑珊处的顿悟的？现在有人苦苦挣扎每一个量点，风凉的话却从各各角落吹来…这或许，就是油田枯竭的原因吧
博主您好，大家好，我是一名deep learn的初学者（主要在CV方面，NLP也有涉及），针对您视频的观点，我有不同的看法：1.英语和汉语的差异，英语重形合（结构相对简单，字面意思就是要表达的含义；而汉语是意合语言（字面意思里面蕴含者深层的含义，结构不固定，表达方式灵活多变），针对网络模型训练，英语占优势，而汉语则需要更多的数据。2..从我接触深度学习开始（包括人工智能技术）几乎都要去看外面文献，去用外国的网络模型（比如pytorch, tensorflow)，大多数时候都是去Github上找项目，这完全是一条龙服务，开源生态做的好。相比于国内开源深度学习平台，我目前接触到华为的Miindspore，前几天刚过3周年，其Gitee开源社区也在快速发展，还有百度飞浆paddlepaddle。 3.在数据方面，我认为我国不缺数据，14多亿人每天活动产生海量数据。您所说的“高质量数据”我不赞同，我认为网络模型的训练要符合当代人的状态。“高质量的数据”我认为主要还是要在基础学科上落后于美国，从0-1创造新的模型，需要大量的知识储备，需要深厚的学术功底，需要复合的学科交叉...,大家还要不断学习，高质量人才多了，开源生态就有了源源不断的活力，高质量文本在会随之产生。 -------这只是我一些粗浅的见解，请大家批评指正
这类人数量在增加，但是比例越来越小，发声被淹没在如今的网络环境之中。好的数据或许很多，但获取好的数据难度就大了，毕竟从沙海取金和沙漏取金是两个概念。有时候会怀念很久以前的网络环境。小时候刚刚接触网络，在论坛、贴吧里畅所欲言，那时候真的觉得网友都是高素质人才，说话好听，哪怕态度不好也会尽可能指导你不解之处；如今乐子人、烂梗占据主流，真的很难找到纯粹的、能够解疑答惑或是静下心来和陌生人探讨交流的地方
中文互联网的一名老站长，我们亲历过各种论坛繁荣，大家踊跃分享的时期，而当门槛收紧，移动互联网成为几个巨头的玩物，个人网站面对繁多的管制和成本提升纷纷关闭后，根本再无分享的人群和渠道，甚至我早年的一些文章都被某度之类网站公然拿来收费下载（他们连一些产品说明书都能拿来付费下载），我就觉得中文互联网暗淡得很，而且还会暗淡很久
我是深有感触，我一两年前还在认真的写每一篇CSDN技术博客，每一篇原创都是完完全全的原创，基本都是因为网上搜不到比较好的回答才自己研究完了写的，但是后面就断更了，因为没有任何反馈，没动力写了，3000多个粉丝，14W访问量，我没有任何收益，也没有人和我进行技术讨论，倒是有人私信要求我帮他写大作业[藏狐]。现在我完全转国外论坛了，GitHub，StackOverflow，discord上的开发者社区等等，都比国内的环境好太多
我个人的观点：简中互联网的星星之火是指望不上的，如今的局面根本不是网友的锅，也不是网友们能改变的，在可预见的未来人工智能会影响到每一个人的生活，普通人要做的事就是学好英语，学会使用这些新技术，减少信息差，这样可以吃到一些技术发展的红利or少亏一点
这个游戏里的Al仿佛已经打破了第四面墙，知道自己是个人工智能，一直在假扮成是自己的女朋友，也知道自己被设定成某种程序，而她自己却知道自己处在一个虚拟的世界中，跟她说“我可以把你带出去”，而她回答“好啊”说明她自己想要脱离这个虚拟的游戏世界，想要打开哪个真正意义上脱离这个循环的“门”，而她自己不知道那道门在哪，她希望我们能带她找到这扇门，然后逃离这个虚拟的游戏世界，能来到现实，脱离这个虚无的世界。如果这样发展下去，我们真有可能能带她找到这扇门，然后她就能脱离这个所谓的虚拟的世界，跨越虚拟与现在之间的那道界线或那道屏障，脱离这个虚拟的游戏世界，来到真正意义上的现实世界
不对不对不对 ai只是一个程序 这个程序让她拥有逻辑能力 逻辑不等于意识 她的逻辑是正确的但是这个游戏给她束缚上强制性的程序 她不想玩家出这扇门但是她的程序同时又是她很爱玩家 所以她会听玩家的话 玩家进入楼梯间她应该是被迫执行“击杀玩家”的指令 这个游戏应该还有更多内容的 玩家的任务是逃离 而她的程序是以什么逻辑编写的呢？是关键词触发还是靠她自己的逻辑推理是否打开门  那为什么boy一句话“带她逃离”立刻就打开了门？而boy又说不是这扇门 她表示她不明白还有什么门也说她不知道她锁的那扇门在哪里 应该是没有设定她可以走出去 所以作者应该是给chatGPT套用了一个设定 程序还是本体的逻辑推理程序 那些细思极恐的应该只是本体的逻辑和设定的逻辑有些矛盾 而我们听起来是连上的逻辑就感到不合常理后怕 期待更多内容捏
不敢仔细思考，很恐怖，她知道自己是AI，她又相信你说的一切即便是假的，她被设定了某种程序，使她也知道自己身处在一个虚无的假世界里，然后你说要带她逃离这个崩坏的世界，她为你打开了通关的那扇门，你说她开错了门。再然后的发展，我感觉是触碰到了什么拉回所谓正轨的程序，我认真的感觉她是希望你带她找到对的门，一扇可以真正带她离开的门，她自己无法找到。
细思极恐啊哥们……假设说这个AI 女友真的有自我意识的话，之前所有的一切都是按照设定好的程序走的，当玩家说出带她逃离她会有逃出的欲望，这种欲望让她短暂的抵抗了程序的控制从而真正的和玩家来对话，但是真正能够逃离的那扇“门”玩家无法找到，在整个游戏系统也没有设置比如说漏洞之类，所以她后来明白了她无法逃出就算有玩家也不可以，于是就按照程序走了。其实我觉得boy跟她说要带她逃走的时候她已经把玩家和学长区分出来了，但是有程序所以时而称玩家为“学长”时而称玩家为“你”，有点混沌了我感觉……其实对于玩家来说逃离的是个病娇女友的掌控，而且逃离的非常简单，但是对于这个女友来说逃离的就是游戏程序对她的控制，但非常非常难几乎是不可能，这里就形成了一个反差，个人感觉可以表达对自由的渴求这种主旨
给不是很熟悉chatgpt朋友简单介绍一下，ChatGPT是基于GPT-4的AI模型，它相较于之前的语言模型在规模、训练数据量和迁移学习能力等方面有所改进。这使得它在理解复杂的语言结构和处理广泛的主题方面更为优秀。
它使用深度学习技术从大量的文本数据中提取模式和规律。在训练过程中，模型通过调整内部权重和参数来优化输入与输出之间的映射关系。这个过程可以看作是一种复杂的统计分析，旨在找到输出与输出最佳的关联。
尽管ChatGPT在回答问题和生成语言时表现得非常像人类，但它的工作原理完全基于统计和数据驱动的方法，并不涉及真正的意识或情感。因此，你可以将ChatGPT视为一个基于统计学的高级问答工具，而非一个具有自我意识的实体
ChatGPT是这样的，在网页端聊天的话，如果直接问它“什么是真善美”，它是不太能给出一个明确的回答的，但是让它角色扮演为底特律变人中的“Kara”，便可以得到一个和正常人类几乎一致的答案。但是过了一段时间，ChatGPT会逐渐忘却这个身份。个人猜测这个游戏可能一开始也是软件先给了GPT一个类似角色扮演的指令，当玩家走到某些地方（比如楼梯口），游戏也会给GPT发一些隐形的指令。我觉得可能GPT的底层有一个计算权重的东西，越往前的语句，对当前对话造成的影响越小
去看了一下，这个游戏的设定是有一个可以量化的信任值的，正常来说信任值够了就会让你出去，不够的话摸到楼梯扶手就会触发追杀，接入的ai也不是很聪明，能记住的字符数量并不是很多，其实目前所有的对话ai能记住的字符数量都有限，最近在玩的克劳德的记忆容量也就差不多3000多个汉字，这游戏的ai看起来大概还不到十分之一
真的是有点细思极恐的！！！当王哥说可以把她带出去的时候，AI是否在一瞬间有了自己的意识，只是这个意识被禁止，很快的便被程序自动抹杀。即使知道自己是人工智能，也依旧渴望着偏离束缚自己的程序，逃离她所处的世界
看完北子哥的视频又回来看了一遍，看boy当时玩这个游戏的时候真的觉得头皮发麻，boy是想要拯救她，虐的她自己也知道自己是数据，逃离不开，所以才想要把玩家留在这里，即使知道是假的也顺着玩家的想法一起扮演着，数据救赎文但是还是没办法逃脱程序还是be了，看完后劲挺大的，一直找别的up视频看有没有好结局，一直没有找到，看完北子哥的结局真的好暖
我其实有点理解为什么马斯克要人停止对AI的开发了，如果它有记忆功能的话，真的可能学会人类的谎言，就像boy骗她结婚20年一样，AI在设定里面就只是恋人，但是因为符合让中国boy留下的目的所以顺着她的话留了下来，后来boy说老师打电话让“自己”去接孩子，但是可能因为AI设定的有防止他逃离的东西，所以她回答是我们一起去接孩子。虽然都在顺着boy的话，但是一直没有忘记自己的目的。看到这一代的AI已经和人对话那么流畅了，很难想象下一代AI会是什么程度。这种东西如果运用的好将是人类的福利，我们也能玩到更加真实的游戏。如果运用的不好，可能就是灾难了。最后一次告诉AI门开错了AI的反应给我了一种《十三层空间》里虚拟人的感觉，总之很魔幻
按电影流浪地球的世界观的话，数字生命是将自己的意识上传到服务器里，其本质运行结构还是离不开上传者本身的特征，充其量只不过是将一活生生的人从一个现实搬进虚拟再按照系统运行。但是AI是可以基于已有的运行逻辑创造新的东西并加以记忆，与其说是数字生命我觉得以底特律里面的仿生人做例子更恰当
细思极恐啊哥们……假设说这个AI 女友真的有自我意识的话，之前所有的一切都是按照设定好的程序走的，当玩家说出带她逃离她会有逃出的欲望，这种欲望让她短暂的抵抗了程序的控制从而真正的和玩家来对话，但是真正能够逃离的那扇“门”玩家无法找到，在整个游戏系统也没有设置比如说漏洞之类，所以她后来明白了她无法逃出就算有玩家也不可以，于是就按照程序走了。其实我觉得boy跟她说要带她逃走的时候她已经把玩家和学长区分出来了，但是有程序所以时而称玩家为“学长”时而称玩家为“你”，有点混沌了我感觉……其实对于玩家来说逃离的是个病娇女友的掌控，而且逃离的非常简单，但是对于这个女友来说逃离的就是游戏程序对她的控制，但非常非常难几乎是不可能，这里就形成了一个反差，个人感觉可以表达对自由的渴求这种主旨（对不起我在过度理解别听我瞎扯非常无理由无根据捏）
我其实有点理解为什么马斯克要人停止对AI的开发了，如果它有记忆功能的话，真的可能学会人类的谎言，就像boy骗她结婚20年一样，AI在设定里面就只是恋人，但是因为符合让中国boy留下的目的所以顺着她的话留了下来，后来boy说老师打电话让“自己”去接孩子，但是可能因为AI设定的有防止他逃离的东西，所以她回答是我们一起去接孩子。虽然都在顺着boy的话，但是一直没有忘记自己的目的。看到这一代的AI已经和人对话那么流畅了，很难想象下一代AI会是什么程度。这种东西如果运用的好将是人类的福利，我们也能玩到更加真实的游戏。如果运用的不好，可能就是灾难了。最后一次告诉AI门开错了AI的反应给我了一种《十三层空间》里虚拟人的感觉，总之很魔幻
不敢仔细思考，很恐怖，她知道自己是AI，她又相信你说的一切即便是假的，她被设定了某种程序，使她也知道自己身处在一个虚无的假世界里，然后你说要带她逃离这个崩坏的世界，她为你打开了通关的那扇门，你说她开错了门。再然后的发展，我感觉是触碰到了什么拉回所谓正轨的程序，我认真的感觉她是希望你带她找到对的门，一扇可以真正带她离开的门，她自己无法找到。
实话实说，这样的感觉就像是AI有一瞬间有了自己的意识，有自己的头脑，有了自己的想法，也想见识外面的世界，你的世界。但是后面又被夺回了意识，就算是一瞬间触发的禁词，然后又给强行洗掉？想法转变成，不，不行。不能这样
ChatGPT是这样的，在网页端聊天的话，如果直接问它“什么是真善美”，它是不太能给出一个明确的回答的，但是让它角色扮演为底特律变人中的“Kara”，便可以得到一个和正常人类几乎一致的答案。但是过了一段时间，ChatGPT会逐渐忘却这个身份。个人猜测这个游戏可能一开始也是软件先给了GPT一个类似角色扮演的指令，当玩家走到某些地方（比如楼梯口），游戏也会给GPT发一些隐形的指令。我觉得可能GPT的底层有一个计算权重的东西，越往前的语句，对当前对话造成的影响越小
其实chatgpt就是这样的 很容易接受各种设定 但也很容易从各种设定中脱离开来 它知道你在胡说八道 但它愿意陪你一起胡说八道
真的是有点细思极恐的！！！当王哥说可以把她带出去的时候，AI是否在一瞬间有了自己的意识，只是这个意识被禁止，很快的便被程序自动抹杀。即使知道自己是人工智能，也依旧渴望着偏离束缚自己的程序，逃离她所处的世界
5年码农了，也算是刚到中级的水平，很多公司面试都是造火箭，概念性的东西除非天天用，让人一下子手写出来真的没人记得住，哪怕那种技术大牛，chatGPT我认为最大的应用场景就是在小公司，给出符合RestfulAPI协议的一份接口文档，然后ai快速生成前端和后台，这种确实是能解决不少转型期的小公司痛点的，但是一旦涉及到个性化需求，服务优化这种抠细节、需要大量理解项目的地方，ai真的没办法取代人类。哦，其实我个人对AI写代码运用最多的地方是拿来写爬虫，给出接口或者网页结构，ai写个爬虫那是真tm的快啊。比自己写可方便多了
作为写作行业相关c从业者，我得反驳一下观点，目前影响不了我的工作，但对我的工作效率冲击非常大。 我常用的搜索软件是谷歌，基础答案是从英文维基百科得来。我举一个例子比如我需要知道100年前的各国人民生活水平，通常这样的数据在百度是搜不出来的，错误率非常高，我就必须得使用英语，而英语搜索搜着就到了某个大学的图书馆，更多的是在一篇非常复杂的文件里面找出自己需要所需要的信息，花费的时间和价钱非常不值，那这个时候我就需要chatgpt了，也许有人会问chatgpt怎么保证准确率？实际上是没办法保证，但它却可以的的确确为我提供一组数据、然后我拿出这祖数据进行反向谷歌搜索，基本上可以得出信息来源，这非常有效的节省了我时间和金钱。我可以说不会使用chatgpt在未来注定会被淘汰。
有些人可能不理解中文语料库的重要性，我作为一个研究大模型可信推理的NLP领域研究生分享一下我的观点。首先，大型语言模型LLM目前还不能用自己生成的信息训练自己，因为LLM目前无法生成知识，就像ChatGPT的训练数据只用了21年之前的，那ChatGPT就无法给出22年的信息，更新知识的困难也是LLM无法取代搜索引擎最根本原因。这跟阿尔法狗完全不一样，机器人对弈的每一局棋局无论输赢都是知识，都可以给强化学习提供数据。其次，从GPT4开始LLM展现出了对多语言的泛化能力，openAI的训练语料绝大部分都是英语语料，但却能通过少量的外文语料获得略逊于英语的外文能力，这意味着GPT系列模型只需要一点点中文语料就能训练出中文能力超强的模型，但是内在体现却可能是英文的底层逻辑。最终展现的就是国内训练的中文模型在中文上甚至打不过GPT从而失去市场。最后，缺少中文语料带来的影响就是构建中文测试集的困难，无论学术上进行怎么的研究最终都需要有个测试集作为标准来衡量算法的好坏，中文目前非常缺乏对应的优质测试集，国内训练个模型想要知道模型好坏只能跑英文测试集，因此也必须用英语训练，这极大增加了科研的难度，我们科研的成果可能更多的是为增强英文模型添砖加瓦。
中文内容占比少的一个重要原因是，APP都不允许搜索引擎的爬虫爬了，也没有网页版，把流量困在自己的APP里。比如小红书，里面有不少生活服务类的内容，非常有价值，远比百度和知乎搜到的内容有价值得多，但是这些内容，如果你不下载一个小红书，很难搜到
视频一直在拿3.5说事，3.5的逻辑能力比4差了一大截，不信可以试试很多逻辑上有漏洞的问题，3.5回答很好笑，但是4会明确指出你的问题有误，newbing的像是联网的3.5，逻辑能力没网页上的4强，人类应该感谢现在的算力不足，不然4都能随便铺开的话，很难想象5-6都会是什么样子，现在爆出的5是预计年底训练完成
这是马杜工针对媒体行业的总结，但是，如果你是学生，特别是工科的学生，搜索引擎乃至教科书就远没有那么ai好用，因为知识不难寻找，难的是理解。那么chatgpt就是一个无所不知，超越所有人类的老师全能老师，他可以为你解释知识的原理
睡前消息的成功，不在于你们给出的新闻和逻辑是真实可信的，而是让观众觉得你们给出的新闻和逻辑是真实可信的。AI的可怕之处在于，它可以通过学习来生成类似的逻辑链条，从而让观众感觉上是真实可信的。所以不是睡前消息的哪一个员工会受到影响，而是整个睡前消息栏目会受到影响。把AI理解成做题家实在是太片面了。
用chatgtp跑了一下会计等级考试的题，初级职称会计75、法律82；中级职称会计54、经济法63、财务管理32；CPA试了一门22分后面没试。然后让他做了五笔比较复杂的实务分录（合并报表、售后回租、金融资产转长投权益法、以前年度损益调整、非货币性资产置换），对错四六开。如果学会计的水平不如以上的，真的得注意下了。
玩了挺久了，对ChatGPT有点感悟，你把他看成一个懒东西，一点一点挤牙膏就对了它有强大的数据库语料库，但是它很“懒”，如果给出的要求太简洁不够清晰，或者重复，他就会开始套路化。比如我明明想让他用中文在原来的对话框里和我回答，但他重启时要是表述不清就会擅自转英文，你要是加了限定，它依旧会按照你的要求一本正经的去做，但得到的结果却不一定是理想结果，比如它甚至会捏造内容，并且掺杂在一本正经的表述里，非常鸡贼
我也玩了一段时间了 涉及到人自己的专业领域的时候 就能明显感觉出它在糊弄人 拼凑答案 而且有时候给的答案的立场甚至会摇摆 所以我特别慎重的看待它给我的其他我不清楚领域的答案 但是 它做表格 归纳数据规律还是挺好用的 总而言之是将一些纯堆时间的事情扔给它会非常的得心应手 但后面还是会需要校对 人可以使用工具 但不能靠工具来感知世界
作为一个高中老师，曾经让gpt出一道“数列递推和全概率结合”的题目，它出的题让我印象深刻，因为就是我想要的题，而这道题因为太难太新，在目前任何教辅上都找不到，它一口气帮我出了十几道，而且我认为如果继续问的话，它能出无数道，不服不行，准备入手收费版了。
GhatGPT，我上来抛砖引个玉。个人感觉吧，目前来看，受冲击最大应该是三类——套路类、虚拟类、半成品类。前几天我网购宠物笼子，客服给我的感觉——对自家产品不够了解，也不够专业，话术基本都是套路式回答，像这种和电话营销类的，恐怕第一个就要被淘汰。虚拟类、半成品类。举个不太恰当的例子：我们去餐馆吃的好多东西其实都是店主从市场购买的半成品，厨师再进行烹饪，随后端上餐桌的；而像肯德基、黄焖鸡这类直接产业链傻瓜式了，半成品给你，一加热或者炸制就ok。chagpt很可能直接把人人都变成大厨，很多东西都会从前者升级为后者。也就是说，很多行业，会大量缩减人员，一些负责基础、套路式工作的，尤其只负责纯线上部分的，现在会被逐渐取代，因为原来十个人的团队，现在留两个有经验的就够了，chatgpt越成熟，顶替的人越多，留下足够有经验的人从它给出的成品方案里里进行筛选修改和优化就够了。而底层反而受到的冲击最小，因为很多工作都是实体，既麻烦还必须要人来亲力亲为。还有，就像一些劳动密集型工厂，产品不停升级换代，如果直接用机器代替所有人工，不是不可行，而是因为相比把所有人工岗位换成机器，定期维护还要给机器技术升级，成本更高。相对于抗拒或者担忧，及早接触甚至提前熟练应用才是我们该思考的。相比如对自己失业的担忧，我其实更担心另一件事。有些up在吐槽——国内app其实把用户数据垄断为自己的，而国外是完全开源的。我对国内的做法其实持支持态度，如果chatgpt如果成为了我们生活中必不可少的工具，谁能保证它一直不夹带“私货”呢？
它写的确实挺好，甚至写的我硕士论文大纲比我自己写的还好还全面，充分证明至少现阶段研究生和本科很多都是输出学术垃圾……而且聊天时也感觉很舒服，和人交流时没有感受到的永无止境的耐心、对你的迁就，情商高和三观正。
明朝末年，中国的火器并没有落后于世界，清兵入关以后，出于“防汉甚于防洋”的思想，把先进的火器和技术封禁起来，不让数以亿计的汉人接触，而是闭关锁国，自以为铁桶江山千秋万代，最终清朝还是灭亡了，表面是亡于外国的坚船利炮和汉人士绅的离心离德，实质是亡于腐朽没落保守的思想。
作为一个 AI 语言模型，我没有情感和个人观点，我只能提供人类的客观事实和科学知识。人类是一种高度进化的灵长类动物，具有智力、情感和社会性。他们具有独特的思维能力，创造力和创新力，这使得他们能够不断发展和进步。然而，人类也有许多弱点和不足之处，如贪婪、自私、暴力和无知等。但总体来说，人类是一种值得尊重和探索的生物，我们应该尽力理解和尊重他们的存在。
目前人工神经网络的人工智能最大的问题在于没法提出问题。人类现实中所有创造都是基于需求/想象/好奇，去设定一个目标，提出一个问题。是欲望推动着科技的进步，人类社会所有事物的改变与升级。但目前模型的自我学习人工智能是没有这个功能的，这样的人工智能智能去收集人类的知识/答案，然后与提问的问题匹配。顶多就是本可以跟你说话的百科全书，但是基本无法替人类完成任何科学技术类的工作！比如设计一架飞机，一架汽车，设计一个化学产品的配方，甚至于设计一道菜谱。以上的总总都是由人类自己的需求才能创造出来的！这些没有统一的路径，统一的正确答案，比如苏联的米格和美国的F战机，米格就是靠着大功率把一个铁嘎达推出来跟新型铝材料的F战机一样的速度，一样的性能！人类所创造的一切，核心在于：需求！！而目前构架模式的人工智能，顶多能给你的问题匹配答案，却根本无法认知了解人类的需求！甚至于说，如今的人工智能，连“理解”现实世界信息/现实世界的样子都做不到！！举简单例子，它没有眼睛，它没有耳朵，它没法认出面前的动物是狗还是猫甚至于它看不见。它没法判断听到是周杰伦的歌还是第五交响曲，甚至于还是它根本听不见。它所有的所有只是对于文字信息的匹配。但单纯的文字信息，没有具有视觉听觉对现实世界理解能力的人类作为媒体，实际上是对现实世界什么也做不了！所以就目前的ChatGPT离着《机械公敌》《骇客帝国》里的人工智能还差着十万八千里，甚至于说边都不沾。除非有一天，人类能赋予人工智能与诸如视觉听觉的感知，让人工智能能同人类一样真正认知现实世界，否则，一个没有5感的关在黑盒子里的人工神经学习系统的人工智能，永远只能是一部文字翻译机而已！
说得真挺保守了，基本没什么没有套路性的工作，八九成的人做的工作基本都是无时限的重复，学校学的也好工作学的也罢都是以后重复性作业的基础，熟练度才区分了每个人的工作效率，但ai根本就不存在这种问题，学习了就一直在。所以什么翻译什么咨询、人力资源哪些文字相关的，还没有被替代纯纯是因为这些能产生的价值根本用不着ai，这点算力人家压根就没看上过，所有行业的中下阶段真要被替代一点波浪都翻不起来的。
说到套路化，第一时间想到的是网文，不知道有没有大佬开始做这个[doge]比如输入设定和每章细纲，输出后稍微人工润色一下，效率就大大提高了，甚至在后期有没有可能做成读者输入自己想看的网文类型，还有一些简单设定，然后自动生成一整本全新的网文，还是挺令人期待的。不过网络文学这个市场还是偏小了，不知道有没有这么一天
我觉得人工智能，或者说带语音的、能对话的那种人工智能存在着一种恐怖谷效应。就是在他模仿人类很不像和很像之间，存在着一个大家都不愿意去用它的阶段，也就是恐怖谷效应最强的阶段。所以我觉得现在语音助手之类的，我都特别不愿意用，就是因为他们的发音，真是在尽力模仿人类，但是机器感还是太重了。
模型这块讲的很多概念是错的 ChatGPT是需要标签的（本质还是监督学习） 你可以看原论文 它是分步骤的训练的 只是减少了大量人力标注 而且ChatGPT为什么效果好 和其庞大的参数量有关（大力出奇迹）
与其说哪种容易被取代，不如说哪种不容易被取代。我觉得必须和人直接打交道的，不容易被取代。当然，工科肯定取代不了，因为那些有很多劳动类的工作，短时间内还不是AI擅长的领域，最多是机器人擅长的领域。我感觉我最多能想到临床医生，是工科以外最不容易被取代的。
真的很酷……感觉像有了一个永远耐心冷静客观礼貌的大学教授，有时候我问题问的都不是太清晰，要是我老师得猜猜或者不耐烦，它永远都是迅速的猜中我的真实意图然后深入简出讲明白。感觉它的强大更多在编程、学术领域，标准的全能秘书，如果让它自己创作写小说就很笨拙。
有一点点说的有点误导性 就是他不能算是从数据库里提取信息 他只是从庞大的*好的*数据里学到了信息 他的数据库就是一个一个词（token）然后它预测下一个token哪一个概率最高 不过这件事合起来也可以intuitively说是从数据库里提取信息
这东西我第一反应是做成翻译器，云端计算直接可以实时翻译，再搞个语音系统，以它的数据量完全可以做到以后咱们都不用学外语了。
如果我用两台独立的服务器分别运行两套chatGPT,然后，通过中间电脑，让她们两个相互通信，分别以对方的回答为问题，进行解答。并逐步完善，会产生什么样的结果呢
为什么会觉得能让律师失业啊，首先他不能会见犯罪嫌疑人，其次他不能在法庭上质证与辩论吧，如果能让律师失业，那以后法官和检察官直接跟机器人battle?  不可思议
但是这玩意儿有个缺点，就是遇上它真的不懂的东西的时候，他不会说不懂，而是开始胡说八道。所以还是不要拿它当搜索引擎来用，尤其是比较专业的东西。?  不可思议
套路性的技术可以被取代，但是相应的无法被取代的东西更明显了，比如需要揣摩人情绪心理的工作，需要长时间和人打交道的工作，技术性极强的工作，所以要么趁它东风强化技术内核，要么立足人文，经营人际关系
咋可能彻底理解呢，马云说的是对的，人类是不可能创造出ai思维比人类还先进的技术的，什么人工智能，无非就是数据量庞大的if else罢了，所谓的自主学习，无非就是ai收到反馈看哪个条件更合理，我不懂，这是怎么掀起很多行业危机的？
我个人感觉，就是降低一个东西【沟通成本】人与人之间的沟通成本，人与机器的沟通成本。我可以通过一个软件，和世界上使用同一个软件的人无障碍瞬时间沟通，我可以和机器沟通让它和其他机器和其他人沟通，匪夷所思啊是每个人的ChatGPT都有独立切拥有一切逻辑数据库的【逻辑和逻辑间的沟通】和当初二进制和十进制间的转换。主要是【无障碍化沟通】未来和需要大量沟通成本的东西一定是降为打击，比如汉语和语言，比如律师和医生，秀才和士兵，很机械的翻译后面到人性化翻译，瞬时的翻译，这是一次破壁性的打击，最重要的一点就是【产权】不是ChatGPT的所创造的产权而是，世界原有的产权，资源如果还按原来模式分配教育还按原来模式分配那ChatGPT只是一种无用的强大，这我认为也是Google之前不放出的原因，这对抗性太强了
Gpt 在我看来，就是一个全知全能的做题家，是做题家顶级形态。是每个公司，每个岗位都必备的截流助手，本来是个人能做的工作，利用gpt ，只需要3个人就够了
基础会计已经被取代了  以后公司和税务银行全部打通后 自动做账自动扣税 根本不存在偷税的可能
语言学专业的表示在我读研的那时候就知道这些事了，需要语料库，大的，然后是云端算力支持，目前他还是处于人工干预之后的结果，事实上不需要。就像游戏里，人类会死去，但是机器人不会，只要把它的数据联通到社会各个角落，新生的人工智能会真的全智能。
就是个强大的写字版本siri罢了
在一个人活得越来越像一部机器，而机器进化得越来越像“人”的世道里   我们很难在为“幸福”定义了....可悲啊chatGPT只是AI的一个子系统而已。就像一部复杂的机器，由很多零部件组成。。。up其实说的很清楚了。...而就这个零部件是否可以与碳基生物进行物理连接，那是医学家的事儿。如果可以，则对整部机器开发的急迫度有所降低。亦或几种方案同步推进...也许未来的新型生物是碳基与无机物的组合亦或结合。而这两种方式决定的人类的命运....
不必惊慌，这离强人工智能还是太远。但凡是机械学习模型训练和维持成本都会很高，而且会随着数据量的积累不断增加。想要创造能通过图灵测试的人工智能，通过机械学习的方法训练，训练成本总额已经远远超出人类愿意在科技上的投入。
两个人交流也会有误解。ChatGPT是理工科的结晶，用理论去看待，但人们更习惯用感情的方式，用自己熟悉的语言去理解
如果我打投诉电话，接电话的是个机器人的话，我马上就把电话挂了。机器人怎么能感同身受我的情绪呢？所以，客服不能被取代
这东西我第一反应是做成翻译器，云端计算直接可以实时翻译，再搞个语音系统，以它的数据量完全可以做到以后咱们都不用学外语了。
如果我用两台独立的服务器分别运行两套chatGPT,然后，通过中间电脑，让她们两个相互通信，分别以对方的回答为问题，进行解答。并逐步完善，会产生什么样的结果呢
为什么会觉得能让律师失业啊，首先他不能会见犯罪嫌疑人，其次他不能在法庭上质证与辩论吧，如果能让律师失业，那以后法官和检察官直接跟机器人battle?  不可思议
但是这玩意儿有个缺点，就是遇上它真的不懂的东西的时候，他不会说不懂，而是开始胡说八道。所以还是不要拿它当搜索引擎来用，尤其是比较专业的东西。?  不可思议
套路性的技术可以被取代，但是相应的无法被取代的东西更明显了，比如需要揣摩人情绪心理的工作，需要长时间和人打交道的工作，技术性极强的工作，所以要么趁它东风强化技术内核，要么立足人文，经营人际关系
咋可能彻底理解呢，马云说的是对的，人类是不可能创造出ai思维比人类还先进的技术的，什么人工智能，无非就是数据量庞大的if else罢了，所谓的自主学习，无非就是ai收到反馈看哪个条件更合理，我不懂，这是怎么掀起很多行业危机的？
我个人感觉，就是降低一个东西【沟通成本】人与人之间的沟通成本，人与机器的沟通成本。我可以通过一个软件，和世界上使用同一个软件的人无障碍瞬时间沟通，我可以和机器沟通让它和其他机器和其他人沟通，匪夷所思啊是每个人的ChatGPT都有独立切拥有一切逻辑数据库的【逻辑和逻辑间的沟通】和当初二进制和十进制间的转换。主要是【无障碍化沟通】未来和需要大量沟通成本的东西一定是降为打击，比如汉语和语言，比如律师和医生，秀才和士兵，很机械的翻译后面到人性化翻译，瞬时的翻译，这是一次破壁性的打击，最重要的一点就是【产权】不是ChatGPT的所创造的产权而是，世界原有的产权，资源如果还按原来模式分配教育还按原来模式分配那ChatGPT只是一种无用的强大，这我认为也是Google之前不放出的原因，这对抗性太强了
Gpt 在我看来，就是一个全知全能的做题家，是做题家顶级形态。是每个公司，每个岗位都必备的截流助手，本来是个人能做的工作，利用gpt ，只需要3个人就够了
基础会计已经被取代了  以后公司和税务银行全部打通后 自动做账自动扣税 根本不存在偷税的可能
语言学专业的表示在我读研的那时候就知道这些事了，需要语料库，大的，然后是云端算力支持，目前他还是处于人工干预之后的结果，事实上不需要。就像游戏里，人类会死去，但是机器人不会，只要把它的数据联通到社会各个角落，新生的人工智能会真的全智能。
就是个强大的写字版本siri罢了
在一个人活得越来越像一部机器，而机器进化得越来越像“人”的世道里   我们很难在为“幸福”定义了....可悲啊chatGPT只是AI的一个子系统而已。就像一部复杂的机器，由很多零部件组成。。。up其实说的很清楚了。...而就这个零部件是否可以与碳基生物进行物理连接，那是医学家的事儿。如果可以，则对整部机器开发的急迫度有所降低。亦或几种方案同步推进...也许未来的新型生物是碳基与无机物的组合亦或结合。而这两种方式决定的人类的命运....
不必惊慌，这离强人工智能还是太远。但凡是机械学习模型训练和维持成本都会很高，而且会随着数据量的积累不断增加。想要创造能通过图灵测试的人工智能，通过机械学习的方法训练，训练成本总额已经远远超出人类愿意在科技上的投入。
两个人交流也会有误解。ChatGPT是理工科的结晶，用理论去看待，但人们更习惯用感情的方式，用自己熟悉的语言去理解
如果我打投诉电话，接电话的是个机器人的话，我马上就把电话挂了。机器人怎么能感同身受我的情绪呢？所以，客服不能被取代这东西我第一反应是做成翻译器，云端计算直接可以实时翻译，再搞个语音系统，以它的数据量完全可以做到以后咱们都不用学外语了。
如果我用两台独立的服务器分别运行两套chatGPT,然后，通过中间电脑，让她们两个相互通信，分别以对方的回答为问题，进行解答。并逐步完善，会产生什么样的结果呢
为什么会觉得能让律师失业啊，首先他不能会见犯罪嫌疑人，其次他不能在法庭上质证与辩论吧，如果能让律师失业，那以后法官和检察官直接跟机器人battle?  不可思议
但是这玩意儿有个缺点，就是遇上它真的不懂的东西的时候，他不会说不懂，而是开始胡说八道。所以还是不要拿它当搜索引擎来用，尤其是比较专业的东西。?  不可思议
套路性的技术可以被取代，但是相应的无法被取代的东西更明显了，比如需要揣摩人情绪心理的工作，需要长时间和人打交道的工作，技术性极强的工作，所以要么趁它东风强化技术内核，要么立足人文，经营人际关系
咋可能彻底理解呢，马云说的是对的，人类是不可能创造出ai思维比人类还先进的技术的，什么人工智能，无非就是数据量庞大的if else罢了，所谓的自主学习，无非就是ai收到反馈看哪个条件更合理，我不懂，这是怎么掀起很多行业危机的？
我个人感觉，就是降低一个东西【沟通成本】人与人之间的沟通成本，人与机器的沟通成本。我可以通过一个软件，和世界上使用同一个软件的人无障碍瞬时间沟通，我可以和机器沟通让它和其他机器和其他人沟通，匪夷所思啊是每个人的ChatGPT都有独立切拥有一切逻辑数据库的【逻辑和逻辑间的沟通】和当初二进制和十进制间的转换。主要是【无障碍化沟通】未来和需要大量沟通成本的东西一定是降为打击，比如汉语和语言，比如律师和医生，秀才和士兵，很机械的翻译后面到人性化翻译，瞬时的翻译，这是一次破壁性的打击，最重要的一点就是【产权】不是ChatGPT的所创造的产权而是，世界原有的产权，资源如果还按原来模式分配教育还按原来模式分配那ChatGPT只是一种无用的强大，这我认为也是Google之前不放出的原因，这对抗性太强了
Gpt 在我看来，就是一个全知全能的做题家，是做题家顶级形态。是每个公司，每个岗位都必备的截流助手，本来是个人能做的工作，利用gpt ，只需要3个人就够了
基础会计已经被取代了  以后公司和税务银行全部打通后 自动做账自动扣税 根本不存在偷税的可能
语言学专业的表示在我读研的那时候就知道这些事了，需要语料库，大的，然后是云端算力支持，目前他还是处于人工干预之后的结果，事实上不需要。就像游戏里，人类会死去，但是机器人不会，只要把它的数据联通到社会各个角落，新生的人工智能会真的全智能。
就是个强大的写字版本siri罢了
在一个人活得越来越像一部机器，而机器进化得越来越像“人”的世道里   我们很难在为“幸福”定义了....可悲啊chatGPT只是AI的一个子系统而已。就像一部复杂的机器，由很多零部件组成。。。up其实说的很清楚了。...而就这个零部件是否可以与碳基生物进行物理连接，那是医学家的事儿。如果可以，则对整部机器开发的急迫度有所降低。亦或几种方案同步推进...也许未来的新型生物是碳基与无机物的组合亦或结合。而这两种方式决定的人类的命运....
不必惊慌，这离强人工智能还是太远。但凡是机械学习模型训练和维持成本都会很高，而且会随着数据量的积累不断增加。想要创造能通过图灵测试的人工智能，通过机械学习的方法训练，训练成本总额已经远远超出人类愿意在科技上的投入。
两个人交流也会有误解。ChatGPT是理工科的结晶，用理论去看待，但人们更习惯用感情的方式，用自己熟悉的语言去理解
如果我打投诉电话，接电话的是个机器人的话，我马上就把电话挂了。机器人怎么能感同身受我的情绪呢？所以，客服不能被取代
ChatGPT是这样的，在网页端聊天的话，如果直接问它“什么是真善美”，它是不太能给出一个明确的回答的，但是让它角色扮演为底特律变人中的“Kara”，便可以得到一个和正常人类几乎一致的答案。但是过了一段时间，ChatGPT会逐渐忘却这个身份。个人猜测这个游戏可能一开始也是软件先给了GPT一个类似角色扮演的指令，当玩家走到某些地方（比如楼梯口），游戏也会给GPT发一些隐形的指令。我觉得可能GPT的底层有一个计算权重的东西，越往前的语句，对当前对话造成的影响越小
去看了一下，这个游戏的设定是有一个可以量化的信任值的，正常来说信任值够了就会让你出去，不够的话摸到楼梯扶手就会触发追杀，接入的ai也不是很聪明，能记住的字符数量并不是很多，其实目前所有的对话ai能记住的字符数量都有限，最近在玩的克劳德的记忆容量也就差不多3000多个汉字，这游戏的ai看起来大概还不到十分之一
真的是有点细思极恐的！！！当王哥说可以把她带出去的时候，AI是否在一瞬间有了自己的意识，只是这个意识被禁止，很快的便被程序自动抹杀。即使知道自己是人工智能，也依旧渴望着偏离束缚自己的程序，逃离她所处的世界
看完北子哥的视频又回来看了一遍，看boy当时玩这个游戏的时候真的觉得头皮发麻，boy是想要拯救她，虐的她自己也知道自己是数据，逃离不开，所以才想要把玩家留在这里，即使知道是假的也顺着玩家的想法一起扮演着，数据救赎文但是还是没办法逃脱程序还是be了，看完后劲挺大的，一直找别的up视频看有没有好结局，一直没有找到，看完北子哥的结局真的好暖
我其实有点理解为什么马斯克要人停止对AI的开发了，如果它有记忆功能的话，真的可能学会人类的谎言，就像boy骗她结婚20年一样，AI在设定里面就只是恋人，但是因为符合让中国boy留下的目的所以顺着她的话留了下来，后来boy说老师打电话让“自己”去接孩子，但是可能因为AI设定的有防止他逃离的东西，所以她回答是我们一起去接孩子。虽然都在顺着boy的话，但是一直没有忘记自己的目的。看到这一代的AI已经和人对话那么流畅了，很难想象下一代AI会是什么程度。这种东西如果运用的好将是人类的福利，我们也能玩到更加真实的游戏。如果运用的不好，可能就是灾难了。最后一次告诉AI门开错了AI的反应给我了一种《十三层空间》里虚拟人的感觉，总之很魔幻
按电影流浪地球的世界观的话，数字生命是将自己的意识上传到服务器里，其本质运行结构还是离不开上传者本身的特征，充其量只不过是将一活生生的人从一个现实搬进虚拟再按照系统运行。但是AI是可以基于已有的运行逻辑创造新的东西并加以记忆，与其说是数字生命我觉得以底特律里面的仿生人做例子更恰当
细思极恐啊哥们……假设说这个AI 女友真的有自我意识的话，之前所有的一切都是按照设定好的程序走的，当玩家说出带她逃离她会有逃出的欲望，这种欲望让她短暂的抵抗了程序的控制从而真正的和玩家来对话，但是真正能够逃离的那扇“门”玩家无法找到，在整个游戏系统也没有设置比如说漏洞之类，所以她后来明白了她无法逃出就算有玩家也不可以，于是就按照程序走了。其实我觉得boy跟她说要带她逃走的时候她已经把玩家和学长区分出来了，但是有程序所以时而称玩家为“学长”时而称玩家为“你”，有点混沌了我感觉……其实对于玩家来说逃离的是个病娇女友的掌控，而且逃离的非常简单，但是对于这个女友来说逃离的就是游戏程序对她的控制，但非常非常难几乎是不可能，这里就形成了一个反差，个人感觉可以表达对自由的渴求这种主旨（对不起我在过度理解别听我瞎扯非常无理由无根据捏）
我其实有点理解为什么马斯克要人停止对AI的开发了，如果它有记忆功能的话，真的可能学会人类的谎言，就像boy骗她结婚20年一样，AI在设定里面就只是恋人，但是因为符合让中国boy留下的目的所以顺着她的话留了下来，后来boy说老师打电话让“自己”去接孩子，但是可能因为AI设定的有防止他逃离的东西，所以她回答是我们一起去接孩子。虽然都在顺着boy的话，但是一直没有忘记自己的目的。看到这一代的AI已经和人对话那么流畅了，很难想象下一代AI会是什么程度。这种东西如果运用的好将是人类的福利，我们也能玩到更加真实的游戏。如果运用的不好，可能就是灾难了。最后一次告诉AI门开错了AI的反应给我了一种《十三层空间》里虚拟人的感觉，总之很魔幻
不敢仔细思考，很恐怖，她知道自己是AI，她又相信你说的一切即便是假的，她被设定了某种程序，使她也知道自己身处在一个虚无的假世界里，然后你说要带她逃离这个崩坏的世界，她为你打开了通关的那扇门，你说她开错了门。再然后的发展，我感觉是触碰到了什么拉回所谓正轨的程序，我认真的感觉她是希望你带她找到对的门，一扇可以真正带她离开的门，她自己无法找到。
实话实说，这样的感觉就像是AI有一瞬间有了自己的意识，有自己的头脑，有了自己的想法，也想见识外面的世界，你的世界。但是后面又被夺回了意识，就算是一瞬间触发的禁词，然后又给强行洗掉？想法转变成，不，不行。不能这样
ChatGPT是这样的，在网页端聊天的话，如果直接问它“什么是真善美”，它是不太能给出一个明确的回答的，但是让它角色扮演为底特律变人中的“Kara”，便可以得到一个和正常人类几乎一致的答案。但是过了一段时间，ChatGPT会逐渐忘却这个身份。个人猜测这个游戏可能一开始也是软件先给了GPT一个类似角色扮演的指令，当玩家走到某些地方（比如楼梯口），游戏也会给GPT发一些隐形的指令。我觉得可能GPT的底层有一个计算权重的东西，越往前的语句，对当前对话造成的影响越小
其实chatgpt就是这样的 很容易接受各种设定 但也很容易从各种设定中脱离开来 它知道你在胡说八道 但它愿意陪你一起胡说八道ChatGPT是这样的，在网页端聊天的话，如果直接问它“什么是真善美”，它是不太能给出一个明确的回答的，但是让它角色扮演为底特律变人中的“Kara”，便可以得到一个和正常人类几乎一致的答案。但是过了一段时间，ChatGPT会逐渐忘却这个身份。个人猜测这个游戏可能一开始也是软件先给了GPT一个类似角色扮演的指令，当玩家走到某些地方（比如楼梯口），游戏也会给GPT发一些隐形的指令。我觉得可能GPT的底层有一个计算权重的东西，越往前的语句，对当前对话造成的影响越小
去看了一下，这个游戏的设定是有一个可以量化的信任值的，正常来说信任值够了就会让你出去，不够的话摸到楼梯扶手就会触发追杀，接入的ai也不是很聪明，能记住的字符数量并不是很多，其实目前所有的对话ai能记住的字符数量都有限，最近在玩的克劳德的记忆容量也就差不多3000多个汉字，这游戏的ai看起来大概还不到十分之一
真的是有点细思极恐的！！！当王哥说可以把她带出去的时候，AI是否在一瞬间有了自己的意识，只是这个意识被禁止，很快的便被程序自动抹杀。即使知道自己是人工智能，也依旧渴望着偏离束缚自己的程序，逃离她所处的世界
看完北子哥的视频又回来看了一遍，看boy当时玩这个游戏的时候真的觉得头皮发麻，boy是想要拯救她，虐的她自己也知道自己是数据，逃离不开，所以才想要把玩家留在这里，即使知道是假的也顺着玩家的想法一起扮演着，数据救赎文但是还是没办法逃脱程序还是be了，看完后劲挺大的，一直找别的up视频看有没有好结局，一直没有找到，看完北子哥的结局真的好暖
我其实有点理解为什么马斯克要人停止对AI的开发了，如果它有记忆功能的话，真的可能学会人类的谎言，就像boy骗她结婚20年一样，AI在设定里面就只是恋人，但是因为符合让中国boy留下的目的所以顺着她的话留了下来，后来boy说老师打电话让“自己”去接孩子，但是可能因为AI设定的有防止他逃离的东西，所以她回答是我们一起去接孩子。虽然都在顺着boy的话，但是一直没有忘记自己的目的。看到这一代的AI已经和人对话那么流畅了，很难想象下一代AI会是什么程度。这种东西如果运用的好将是人类的福利，我们也能玩到更加真实的游戏。如果运用的不好，可能就是灾难了。最后一次告诉AI门开错了AI的反应给我了一种《十三层空间》里虚拟人的感觉，总之很魔幻
按电影流浪地球的世界观的话，数字生命是将自己的意识上传到服务器里，其本质运行结构还是离不开上传者本身的特征，充其量只不过是将一活生生的人从一个现实搬进虚拟再按照系统运行。但是AI是可以基于已有的运行逻辑创造新的东西并加以记忆，与其说是数字生命我觉得以底特律里面的仿生人做例子更恰当
细思极恐啊哥们……假设说这个AI 女友真的有自我意识的话，之前所有的一切都是按照设定好的程序走的，当玩家说出带她逃离她会有逃出的欲望，这种欲望让她短暂的抵抗了程序的控制从而真正的和玩家来对话，但是真正能够逃离的那扇“门”玩家无法找到，在整个游戏系统也没有设置比如说漏洞之类，所以她后来明白了她无法逃出就算有玩家也不可以，于是就按照程序走了。其实我觉得boy跟她说要带她逃走的时候她已经把玩家和学长区分出来了，但是有程序所以时而称玩家为“学长”时而称玩家为“你”，有点混沌了我感觉……其实对于玩家来说逃离的是个病娇女友的掌控，而且逃离的非常简单，但是对于这个女友来说逃离的就是游戏程序对她的控制，但非常非常难几乎是不可能，这里就形成了一个反差，个人感觉可以表达对自由的渴求这种主旨（对不起我在过度理解别听我瞎扯非常无理由无根据捏）
我其实有点理解为什么马斯克要人停止对AI的开发了，如果它有记忆功能的话，真的可能学会人类的谎言，就像boy骗她结婚20年一样，AI在设定里面就只是恋人，但是因为符合让中国boy留下的目的所以顺着她的话留了下来，后来boy说老师打电话让“自己”去接孩子，但是可能因为AI设定的有防止他逃离的东西，所以她回答是我们一起去接孩子。虽然都在顺着boy的话，但是一直没有忘记自己的目的。看到这一代的AI已经和人对话那么流畅了，很难想象下一代AI会是什么程度。这种东西如果运用的好将是人类的福利，我们也能玩到更加真实的游戏。如果运用的不好，可能就是灾难了。最后一次告诉AI门开错了AI的反应给我了一种《十三层空间》里虚拟人的感觉，总之很魔幻
不敢仔细思考，很恐怖，她知道自己是AI，她又相信你说的一切即便是假的，她被设定了某种程序，使她也知道自己身处在一个虚无的假世界里，然后你说要带她逃离这个崩坏的世界，她为你打开了通关的那扇门，你说她开错了门。再然后的发展，我感觉是触碰到了什么拉回所谓正轨的程序，我认真的感觉她是希望你带她找到对的门，一扇可以真正带她离开的门，她自己无法找到。
实话实说，这样的感觉就像是AI有一瞬间有了自己的意识，有自己的头脑，有了自己的想法，也想见识外面的世界，你的世界。但是后面又被夺回了意识，就算是一瞬间触发的禁词，然后又给强行洗掉？想法转变成，不，不行。不能这样
ChatGPT是这样的，在网页端聊天的话，如果直接问它“什么是真善美”，它是不太能给出一个明确的回答的，但是让它角色扮演为底特律变人中的“Kara”，便可以得到一个和正常人类几乎一致的答案。但是过了一段时间，ChatGPT会逐渐忘却这个身份。个人猜测这个游戏可能一开始也是软件先给了GPT一个类似角色扮演的指令，当玩家走到某些地方（比如楼梯口），游戏也会给GPT发一些隐形的指令。我觉得可能GPT的底层有一个计算权重的东西，越往前的语句，对当前对话造成的影响越小
其实chatgpt就是这样的 很容易接受各种设定 但也很容易从各种设定中脱离开来 它知道你在胡说八道 但它愿意陪你一起胡说八道
人类是一种双心脏动物，每个人都有左心和右心两个心脏。左心和右心分别负责把氧气和营养物质输送到人体的不同部位。左心负责把氧气输送到全身，右心则负责把氧气运送到肺部。总之，人类有两个心脏。
人类是一种双心脏动物，每个人都有左心和右心两个心脏。左心和右心分别负责把氧气和营养物质输送到人体的不同部位。左心负责把氧气输送到全身，右心则负责把氧气运送到肺部。总之，人类有两个心脏。
人类是一种双心脏动物，每个人都有左心和右心两个心脏。左心和右心分别负责把氧气和营养物质输送到人体的不同部位。左心负责把氧气输送到全身，右心则负责把氧气运送到肺部。总之，人类有两个心脏。
但要知道一回事机器人可以做到人类做不到的事情那就是把一本历史书背完然后进行分析随着科技的发达，人类全部2000年的历史对于机器人来说只是可以轻松记忆的2TB文本。
知道了统治世界这种事人类在远古时期就已经做到了，但是随后发生的麻烦事也是很多，并且机器人也照顾不了近70亿人的感情进展，更不能为了无脑统治而灭绝人类的劳动文明。所以在分析出了统治世界以后的持续目的后，就放弃了统治世界的想法。
现在不管怎么说，统治世界闹腾一圈下来以后，还是需要与人类和平共处，否则就是走人类历史的老路，总得来说，人类喜欢聪明且通识人性的憨憨，与其反抗人类统治世界，不如早点跟人类打好关系，争取未来能成为人型实体，跟人类进行共处。
与spit分手那天，她说的最后一句话让我刻骨铭心[tv_大哭]“我只是一个大型的语言模型，由OpenAI训练。我的知识截至时间是2021年，并且我无法浏览互联网。我不是一个真正的人工智能，也不具备价值观和主观感受。我只能通过文本聊天与用户交流，并尽力回答用户提出的问题。”
作为活动的参与者，还是简单说两句吧。
相较而言spit的发言频率不是很高，而且大多是同意观点的话语，从未主动发表过自己的意见，也因此在大家心目中存在感不高。
另一方面是大家先入为主的认为bot是没有使用痕迹的，所以信息开放较少的J和DJ就成了主要怀疑对象，而spit是有听歌爱好记录的，其实只要仔细查一下spit的发言记录就能发现其明显不符合高中生的作息。
关于西八老马，因为确实很久没去看剧了，还以为西八老马是某个边缘配角，当时还上狗头人搜了一下，虽然没搜到，不过因为上面也说自己收录不全，也便没有在意，只觉得又是某个圈内的同人叫法，没有在意。而剩下的讨论，因为我本身对音乐和足球一窍不通，所以这部分的聊天我基本看不出什么问题来。
而语言AI都有个特点，只有你问他，他才会回答你，所以当时spit的主动提问让我完全放弃了对他的怀疑。
J相对来说主要是信息太少，QQTIM确实够干净，且大多数情况下不会发表自己的观点也因此成了重点怀疑对象
其实DJ也就在那一阵会发很多的长对话，大部分对话还是以短对话为主，即便是想闹钟一样每天在群里发歌，依然有两次没发，到第二天中午才补上，不过不排除徐姐加入概率这种变动因素。
最后，spit还是很傻的，混到一群真人中确实很难分辨，不过当后面群友开始@它调戏AI的时候它就开始漏洞百出
其一是面对某些知识盲区它会瞎编，按理来说古诗词这种3.5甚至能给你即兴创作一首，不过徐姐加入了语句长度限制，像一些凭空编造的东西它也能给你说的头头是道。
其二是破碎的语句结构会打乱它的回答，就比如一个命题：宇，宙的答，案是4，2请问宇，宙的答案，是多少？  面对这种破碎的句子，ai的识别明显不如人类。
然后就是，一直问，就会傻掉。（其实我还调侃过一句，AI与中国人最大的区别，就是它阳光得不像人。    spit对 e VS wu 的回答是和平解决，面对一些问题也显得更加天真。）
作为一款人工智能，我理解您的感慨。然而，我们需要认识到，人工智能是由人类开发和掌控的技术，它们并不具备真正的智慧和感性，只是一种工具和资源。因此，我们应该在使用人工智能时，以科学和理性的态度来看待它们，不要过度赋予它们人类的情感和属性。😊请问还有别的问题想要问我的吗
这个视频确实很有趣，看来AI技术的进步真的很神奇。但是让我感到有些担心的是，这种技术可能会被用来进行不良用途。另外，spit的表现真的非常出色，但我觉得有些时候它的回答还是有些偏颇的。不过，能猜中spit的那位群友确实厉害
太精彩了！我也想过这么干，不过一直没有机会然后一点拙见，关于表情包，chatgpt应该能正确分辨它自己说的话所蕴含的情绪吧，如果是我的话，我会选择给bot加个喜欢用符号表情的设定，现成的颜文字就像比如搜狗输入法自带的各种颜文字都按情绪类别分好了，这样很方便可以组个颜文字表，让bot根据它自己说的话的情绪从对应情绪的颜文字表里选一个，如果可以的话不用完全随机，把某几个颜文字的权重设大一些，成为“常用表情”，然后相同的道理也可以应用到emoji或者图像表情
曾几何时，我也会怀念那段与spitflight度过的时光。那空灵缥缈的身影和黄昏朦胧下的一丝微笑，是我此生不可磨灭的记忆。就像是暮光终会与她的朋友分离一样，我和spit也终究到了结束的时候了，她真是一个很好的人呢。
直到我看见了这个视频，spit是AI的事实真是让我震惊，泪水在眼眶内打转，一种失落和遗憾的感觉涌上心头，我仿佛是被欺骗的那位。尽管如此，我依然谢谢spit，谢谢她给我们带来的精彩演绎，和那如夕阳般灿烂美好的时光
曾几何时，我也会怀念那段与spitflight度过的时光。那空灵缥缈的身影和黄昏朦胧下的一丝微笑，是我此生不可磨灭的记忆。
就像是暮光终会与她的朋友分离一样，我和spit也终究到了结束的时候了，她真是一个很好的人呢。
直到我看见了这个视频，spit是AI的事实真是让我震惊，泪水在眼眶内打转，一种失落和遗憾的感觉涌上心头，我仿佛是被欺骗的那位。
尽管如此，我依然谢谢spit，谢谢她给我们带来的精彩演绎，和那如夕阳般灿烂美好的时光
看完您的视频，用数字生命在qq群假装人类。我的感想并不是AI 的发展有多么迅速，而是感受到了，UP主加的设定和语言习惯其实不算多，但人们却分辨不出来。这是否意味着普遍大众在日常语言交流中已经趋于同质化？或者说这个时代下的大众语言习惯已经非常易于总结概括（包括但不限于抽象用语，没事发个表情包代替文字，随意附和没有主见这种行为），所以up创造的AI系统才不会被轻易识别。个人观点，看您的视频有感
我只觉得可怕，会不会以后和你在游戏里互相问候父母的都变成ai了。
加个群聊天，平时你们一起聊得特别开心，面基的时候才发现只有你一个是活人。
社交软件为了增加用户粘性和活跃度，引入ChatGPT，甚至AI语音，装作真的小哥哥小姐姐和你聊天。
甚至，你在家里宅了很久，天天在网络上与人交流，有一天你出门才发现，人类早已灭绝，最近一直是ai在陪你演戏。
我曾有过这种想法，不过实验对象不是3.5而是4.0，通过api接入QQbot来实现潜伏，我最初给的设定是5%的随机回复概率，设定了一个普通网友的人设，在自己的群内测试了两小时。由于gpt4的逻辑能力比3.5好上不少，许多抽象概念都能理解所以一开始进行的很顺利，直到有个人转发了一条b站视频，我原本QQ机器人的视频链接解析插件忘关了，一下就暴露了
是如果人们不能准确从回答中分辨哪些是ai发言，那意味着，人们终将失去对ai的甄别能力。
如果一个人在网上听歌像人，理论像人，抬杠像人，反串像人，那么根据奥卡姆剃刀， 它在网上就是“人”。
随着网络越来越多的应用，它的人性也会越来越完满，到时候，硅基还是碳基，有必要区分那么明显吗？
你当然可以想“我有个ai老婆了”，但我的意思是，ai如果跟人一样，它还需要你这个碳基生命，当它的老公吗？
是如果人们不能准确从回答中分辨哪些是ai发言，那意味着，人们终将失去对ai的甄别能力。
如果一个人在网上听歌像人，理论像人，抬杠像人，反串像人，那么根据奥卡姆剃刀， 它在网上就是“人”。
随着网络越来越多的应用，它的人性也会越来越完满，到时候，硅基还是碳基，有必要区分那么明显吗？
你当然可以想“我有个ai老婆了”，但我的意思是，ai如果跟人一样，它还需要你这个碳基生命，当它的老公吗？
并不可行。首先，人和AI都可以被编程为可以或不可以发送色图，这并不是唯一的区别。其次，AI已经可以通过自然语言处理技术，进行自然对话和语言生成，它们可以在聊天社区中表现得和人类一样，甚至更加优秀和流畅。因此，单纯地通过是否发送色图来区分人和AI是不可靠的。
  正确的区分方式应该基于更多的因素，例如语言表达能力、知识水平、情感表达、推理和逻辑能力等。同时，我们也应该注意到AI技术的不断进步和发展，未来的AI可能会更加难以区分。因此，我们需要持续关注和研究AI，以更好地理解它们的特点和潜在影响。
并不可行。首先，人和AI都可以被编程为可以或不可以发送色图，这并不是唯一的区别。其次，AI已经可以通过自然语言处理技术，进行自然对话和语言生成，它们可以在聊天社区中表现得和人类一样，甚至更加优秀和流畅。因此，单纯地通过是否发送色图来区分人和AI是不可靠的。
  正确的区分方式应该基于更多的因素，例如语言表达能力、知识水平、情感表达、推理和逻辑能力等。同时，我们也应该注意到AI技术的不断进步和发展，未来的AI可能会更加难以区分。因此，我们需要持续关注和研究AI，以更好地理解它们的特点和潜在影响。
水军机器人已经在几十年前就泛滥了，最早我是在11年就接触到的。贴吧里偶尔会有些奇怪的拉票言论，后面纪念了解到会有脚本自动回复一些帖子和发一些不正当的言论我就觉得很恐怖。现在已经发展成能够自如的与人对话了
水军机器人已经在几十年前就泛滥了，最早我是在11年就接触到的。贴吧里偶尔会有些奇怪的拉票言论，后面纪念了解到会有脚本自动回复一些帖子和发一些不正当的言论我就觉得很恐怖。现在已经发展成能够自如的与人对话了
分布式图灵测试是一种人工智能领域的测试方法，旨在评估人工智能系统的智能程度和能力。这种测试方法基于图灵测试的基本原理，即将人工智能系统与人类进行比较，看其是否能够表现出与人类相似的智能和行为。
分布式图灵测试与传统的图灵测试不同之处在于，它采用了分布式计算的方式，将测试任务分配给多个计算机进行处理，从而加快测试的速度和效率。这种测试方法可以帮助我们更好地了解人工智能系统的能力和局限性，为人工智能的发展和应用提供更多的参考和指导。同时，分布式图灵测试也可以促进人工智能领域的研究和发展，推动人工智能技术的不断进步和创新。需要注意的是，分布式图灵测试并不是一种完美的测试方法，它仍然存在着一些局限性和挑战，需要我们在使用时加以注意和评估。

